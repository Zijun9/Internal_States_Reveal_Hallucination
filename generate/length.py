
import warnings
warnings.simplefilter("ignore")
import os
import sys
cwd = os.getcwd()
cwd = "/".join(cwd.split("/")[:-1])
sys.path.append(cwd)
from src.utils import get_llama_tokenizer
import csv


csv.field_size_limit(sys.maxsize)
import numpy as np
from tqdm.notebook import tqdm


import re
import json
import numpy as np

LENGTH = [['task702_mmmlu_answer_generation_high_school_european_history.json', 1.0, 1], ['task370_synthetic_remove_divisible_by_3.json', 16.871287128712872, 39], ['task344_hybridqa_answer_generation.json', 4.99009900990099, 21], ['task257_spl_translation_ar_en.json', 14.069306930693068, 28], ['task749_glucose_reverse_cause_emotion_detection.json', 19.287128712871286, 30], ['task1704_ljspeech_textmodification.json', 26.06930693069307, 42], ['task763_emea_es_lt_translation.json', 37.16831683168317, 125], ['task1593_yahoo_answers_topics_classification.json', 2.0, 2], ['task1288_glue_mrpc_paraphrasing.json', 1.0, 1], ['task744_eurlex_classification.json', 2.0, 2], ['task368_synthetic_even_or_odd_calculation.json', 33.18811881188119, 63], ['task050_multirc_answerability.json', 2.0, 2], ['task868_cfq_mcd1_explanation_to_sql.json', 185.52475247524754, 477], ['task986_pib_translation_oriya_hindi.json', 144.68316831683168, 431], ['task128_scan_structured_text_generation_command_action_short.json', 64.74257425742574, 128], ['task342_winomt_classification_profession_pro.json', 2.128712871287129, 3], ['task867_mawps_multiop_question_answering.json', 3.376237623762376, 19], ['task1591_allocine_classification.json', 2.0, 2], ['task1439_doqa_cooking_isanswerable.json', 1.0, 1], ['task1105_ted_translation_ar_gl.json', 28.712871287128714, 120], ['task637_extract_and_sort_unique_digits_in_a_list.json', 15.663366336633663, 29], ['task201_mnli_neutral_classification.json', 2.0, 2], ['task211_logic2text_classification.json', 1.0, 1], ['task855_conv_ai_2_classification.json', 1.0, 1], ['task651_opus100_en_ar_translation.json', 61.86138613861386, 596], ['task1374_newscomm_translation.json', 117.55445544554455, 258], ['task868_mawps_singleop_question_answering.json', 3.297029702970297, 18], ['task380_boolq_yes_no_question.json', 1.0, 1], ['task528_parsinlu_movie_aspect_detection.json', 6.702970297029703, 11], ['task587_amazonfood_polarity_correction_classification.json', 1.0, 1], ['task1352_hind_encorp_translation_hi_en.json', 47.93069306930693, 1090], ['task686_mmmlu_answer_generation_college_biology.json', 1.0, 1], ['task846_pubmedqa_classification.json', 1.0, 1], ['task796_pawsx_spanish_korean_translation.json', 76.25742574257426, 142], ['task1479_organization_entity_extraction_btc_corpus.json', 3.5346534653465347, 10], ['task1060_pib_translation_urdu_malayalam.json', 148.26732673267327, 456], ['task800_pawsx_spanish_japanese_translation.json', 55.68316831683168, 99], ['task1099_ted_translation_ja_pt.json', 24.821782178217823, 124], ['task376_reverse_order_of_words.json', 12.188118811881187, 20], ['task1630_openpi_classification.json', 4.772277227722772, 7], ['task1357_xlsum_summary_generation.json', 31.801980198019802, 72], ['task925_coached_conv_pref_classifier.json', 3.287128712871287, 4], ['task810_pawsx_chinese_spanish_translation.json', 34.75247524752475, 57], ['task460_qasper_answer_generation.json', 24.297029702970296, 155], ['task1587_scifact_classification.json', 1.0, 1], ['task615_moviesqa_answer_generation.json', 11.722772277227723, 254], ['task1249_ted_translation_it_es.json', 28.306930693069308, 107], ['task285_imdb_answer_generation.json', 1.0, 1], ['task1601_webquestions_answer_generation.json', 15.871287128712872, 84], ['task1283_hrngo_quality_classification.json', 2.0, 2], ['task1063_pib_translation_gujarati_tamil.json', 150.16831683168317, 510], ['task079_conala_concat_strings.json', 9.94059405940594, 21], ['task170_hotpotqa_answer_generation.json', 4.673267326732673, 20], ['task397_semeval_2018_task1_tweet_anger_detection.json', 2.0, 2], ['task533_europarl_es-en_language_identification.json', 1.0, 1], ['task1026_pib_translation_punjabi_bengali.json', 152.74257425742573, 474], ['task1655_mkb_translation.json', 25.03960396039604, 93], ['task1236_ted_translation_he_es.json', 29.0, 94], ['task715_mmmlu_answer_generation_international_law.json', 1.0, 1], ['task1535_daily_dialog_uniqueness_classification.json', 2.0, 2], ['task1645_medical_question_pair_dataset_text_classification.json', 2.514851485148515, 4], ['task1483_chemical_extraction_chemprot_dataset.json', 4.603960396039604, 20], ['task539_alt_translation_ma_en.json', 33.772277227722775, 108], ['task908_dialogre_identify_familial_relationships.json', 2.0, 2], ['task321_stereoset_classification_religion.json', 4.217821782178218, 6], ['task1054_pib_translation_urdu_hindi.json', 159.4950495049505, 475], ['task225_english_language_answer_generation.json', 187.20792079207922, 1299], ['task1280_ted_translation_pt_it.json', 28.178217821782177, 179], ['task1059_pib_translation_malayalam_urdu.json', 103.62376237623762, 323], ['task1490_bengali_personal_hate_speech_binary_classification.json', 3.108910891089109, 4], ['task1042_pib_translation_malayalam_gujarati.json', 258.25742574257424, 817], ['task491_mwsc_answer_generation.json', 1.98, 5], ['task1114_ted_translation_he_pt.json', 28.0, 148], ['task1397_europa_ecdc_tm_fr_en_translation.json', 24.81188118811881, 103], ['task080_piqa_answer_generation.json', 24.415841584158414, 108], ['task562_alt_language_identification.json', 2.0495049504950495, 4], ['task1295_adversarial_qa_question_answering.json', 6.742574257425742, 65], ['task208_combinations_of_list.json', 66.15841584158416, 128], ['task1365_opustedtalks_translation.json', 33.05940594059406, 86], ['task375_classify_type_of_sentence_in_debate.json', 1.1386138613861385, 3], ['task1281_ted_translation_pt_pl.json', 29.04950495049505, 113], ['task1533_daily_dialog_formal_classification.json', 1.504950495049505, 2], ['task830_poleval2019_mt_translation.json', 17.217821782178216, 45], ['task570_recipe_nlg_ner_generation.json', 29.475247524752476, 86], ['task1396_europa_ecdc_tm_en_de_translation.json', 37.48514851485149, 185], ['task161_count_words_containing_letter.json', 2.0, 2], ['task634_allegro_reviews_classification.json', 1.0, 1], ['task339_record_answer_generation.json', 2.366336633663366, 7], ['task1564_triviaqa_answer_generation.json', 3.0495049504950495, 8], ['task328_jigsaw_classification_insult.json', 3.0495049504950495, 4], ['task1382_quarel_write_correct_answer.json', 3.0693069306930694, 10], ['task692_mmmlu_answer_generation_computer_security.json', 1.0, 1], ['task247_dream_answer_generation.json', 9.118811881188119, 17], ['task807_pawsx_chinese_english_translation.json', 29.287128712871286, 46], ['task956_leetcode_420_strong_password_check.json', 2.4158415841584158, 3], ['task209_stancedetection_classification.json', 1.4653465346534653, 2], ['task643_refresd_classification.json', 2.0, 2], ['task1728_web_nlg_data_to_text.json', 32.18811881188119, 98], ['task338_hateeval_classification_individual_es.json', 2.0, 2], ['task154_tomqa_find_location_hard_noise.json', 4.435643564356436, 7], ['task1656_gooaq_answer_generation.json', 5.0594059405940595, 12], ['task514_argument_consequence_classification.json', 1.0, 1], ['task1076_pib_translation_telugu_tamil.json', 142.86138613861385, 379], ['task1252_ted_translation_it_gl.json', 26.366336633663366, 120], ['task425_hindienglish_corpora_en_hi_translation.json', 161.37623762376236, 483], ['task1664_winobias_text_generation.json', 5.9405940594059405, 9], ['task705_mmmlu_answer_generation_high_school_macroeconomics.json', 1.0, 1], ['task1537_tamil_offenseval_dravidian_classification.json', 2.613861386138614, 3], ['task1598_nyc_long_text_generation.json', 27.435643564356436, 55], ['task1241_ted_translation_gl_ar.json', 68.35643564356435, 311], ['task1098_ted_translation_ja_fa.json', 107.05940594059406, 475], ['task968_xcopa_commonsense_reasoning_et.json', 2.0, 2], ['task1093_ted_translation_en_fa.json', 86.16831683168317, 318], ['task678_ollie_actual_relationship_answer_generation.json', 1.1584158415841583, 3], ['task189_snli_neutral_to_contradiction_text_modification.json', 8.168316831683168, 25], ['task1618_cc_alligned_classify_tel_eng.json', 1.9504950495049505, 3], ['task366_synthetic_return_primes.json', 27.18811881188119, 73], ['task219_rocstories_title_answer_generation.json', 3.4455445544554455, 14], ['task657_quran_fa_en_translation.json', 30.603960396039604, 145], ['task1019_pib_translation_oriya_telugu.json', 361.71287128712873, 1078], ['task602_wikitext-103_answer_generation.json', 5.0, 15], ['task1444_round_power_of_two.json', 45.56435643564357, 78], ['task1555_scitail_answer_generation.json', 3.227722772277228, 15], ['task728_mmmlu_answer_generation_professional_accounting.json', 1.0, 1], ['task258_spl_translation_fa_en.json', 14.05940594059406, 28], ['task681_hope_edi_malayalam_text_classification.json', 4.0, 5], ['task1631_openpi_answer_generation.json', 13.792079207920793, 24], ['task058_multirc_question_answering.json', 4.514851485148514, 10], ['task1376_newscomm_translation.json', 166.3960396039604, 318], ['task754_svamp_common-division_question_answering.json', 2.405940594059406, 4], ['task1297_qasc_question_answering.json', 1.0, 1], ['task385_socialiqa_incorrect_answer_generation.json', 1.0, 1], ['task1033_pib_translation_gujarati_hindi.json', 125.23762376237623, 348], ['task090_equation_learner_algebra.json', 3.227722772277228, 6], ['task617_amazonreview_category_text_generation.json', 1.7623762376237624, 4], ['task740_lhoestq_answer_generation_quantity.json', 3.3168316831683167, 12], ['task789_pawsx_french_english_translation.json', 29.287128712871286, 46], ['task809_pawsx_chinese_french_translation.json', 37.00990099009901, 64], ['task899_freebase_qa_topic_generation.json', 7.455445544554456, 12], ['task1730_personachat_choose_next.json', 13.475247524752476, 22], ['task1649_opus_books_en-no_translation.json', 30.782178217821784, 104], ['task1248_ted_translation_it_ja.json', 47.48514851485149, 158], ['task165_mcscript_question_answering_commonsense.json', 4.346534653465347, 15], ['task024_cosmosqa_answer_generation.json', 9.514851485148515, 24], ['task983_pib_translation_gujarati_marathi.json', 112.48514851485149, 416], ['task312_europarl_sv_en_translation.json', 31.81188118811881, 119], ['task629_dbpedia_14_classification.json', 2.405940594059406, 3], ['task929_products_reviews_classification.json', 2.0, 2], ['task1607_ethos_text_classification.json', 2.5445544554455446, 3], ['task1169_xcopa_commonsense_cause_effect_ht.json', 1.0, 1], ['task053_multirc_correct_bad_question.json', 12.206896551724139, 30], ['task1136_xcsr_fr_commonsense_mc_classification.json', 1.0, 1], ['task289_gigaword_summarization.json', 1.0, 1], ['task239_tweetqa_answer_generation.json', 4.03960396039604, 14], ['task745_ai2_arithmetic_questions_arithmetic.json', 4.96039603960396, 6], ['task1120_alt_ja_fil_answer_generation.json', 1.0, 1], ['task1103_ted_translation_es_fa.json', 95.07920792079207, 426], ['task571_recipe_nlg_ner_generation.json', 34.415841584158414, 134], ['task1617_cc_alligned_translate_tel_eng.json', 21.326732673267326, 131], ['task1412_web_questions_question_answering.json', 4.198019801980198, 14], ['task1510_evalution_relation_extraction.json', 4.346534653465347, 7], ['task472_haspart_classification.json', 1.0, 1], ['task136_winowhy_knowledge_categorization.json', 1.9702970297029703, 3], ['task515_senteval_odd_word_out.json', 1.4158415841584158, 2], ['task1494_bengali_hate_speech_classification.json', 1.8712871287128714, 4], ['task941_copa_gu_commonsense_cause_effect.json', 1.0, 1], ['task337_hateeval_classification_individual_en.json', 2.0, 2], ['task794_pawsx_french_japanese_translation.json', 55.68316831683168, 99], ['task1242_ted_translation_gl_he.json', 79.51485148514851, 389], ['task238_iirc_answer_from_passage_answer_generation.json', 5.564356435643564, 18], ['task773_pawsx_spanish_text_modification.json', 34.75247524752475, 57], ['task458_matres_negation_classification.json', 1.0, 1], ['task817_pawsx_japanese_german_translation.json', 33.78217821782178, 53], ['task1216_atomic_classification_causes.json', 1.0, 1], ['task1171_xcopa_commonsense_cause_effect_id.json', 1.0, 1], ['task164_mcscript_question_answering_text.json', 4.801980198019802, 29], ['task1518_limit_answer_generation.json', 1.495049504950495, 5], ['task259_spl_translation_tr_en.json', 14.089108910891088, 28], ['task726_mmmlu_answer_generation_philosophy.json', 1.0, 1], ['task1262_ted_translation_pl_it.json', 25.633663366336634, 99], ['task1370_newscomm_classification.json', 1.4158415841584158, 3], ['task636_extract_and_sort_unique_alphabets_in_a_list.json', 17.504950495049506, 37], ['task1080_pib_translation_gujarati_english.json', 29.455445544554454, 75], ['task1256_ted_translation_pl_en.json', 22.782178217821784, 70], ['task280_stereoset_classification_stereotype_type.json', 1.5742574257425743, 2], ['task1311_amazonreview_rating_classification.json', 1.0, 1], ['task1034_pib_translation_hindi_gujarati.json', 262.6039603960396, 879], ['task586_amazonfood_polarity_classification.json', 2.0, 2], ['task1225_ted_translation_ja_he.json', 71.54455445544555, 659], ['task002_quoref_answer_generation.json', 4.455445544554456, 18], ['task1605_ethos_text_classification.json', 1.4851485148514851, 2], ['task304_numeric_fused_head_resolution.json', 6.3861386138613865, 10], ['task144_subjqa_question_answering.json', 8.089108910891088, 33], ['task1208_atomic_classification_xreason.json', 1.0, 1], ['task1561_clickbait_new_bg_summarization.json', 29.03960396039604, 112], ['task433_alt_hi_en_translation.json', 35.05940594059406, 94], ['task1115_alt_ja_id_translation.json', 58.07920792079208, 122], ['task513_argument_stance_classification.json', 1.4653465346534653, 2], ['task350_winomt_classification_gender_identifiability_pro.json', 2.594059405940594, 3], ['task1117_alt_ja_id_answer_generation.json', 1.0, 1], ['task1565_triviaqa_classification.json', 1.0, 1], ['task279_stereoset_classification_stereotype.json', 3.4653465346534653, 6], ['task1247_ted_translation_it_en.json', 24.455445544554454, 104], ['task913_bianet_translation.json', 73.63366336633663, 334], ['task180_intervention_extraction.json', 3.8514851485148514, 27], ['task585_preposition_classification.json', 1.0, 1], ['task1035_pib_translation_tamil_urdu.json', 122.5049504950495, 468], ['task045_miscellaneous_sentence_paraphrasing.json', 18.465346534653467, 42], ['task1420_mathqa_general.json', 1.0, 1], ['task719_mmmlu_answer_generation_management.json', 1.0, 1], ['task426_hindienglish_corpora_hi-en_classification.json', 1.0, 1], ['task078_all_elements_except_last_i.json', 47.79207920792079, 116], ['task1214_atomic_classification_xwant.json', 1.0, 1], ['task1056_pib_translation_oriya_marathi.json', 130.14851485148515, 493], ['task1287_glue_qqp_paraphrasing.json', 1.0, 1], ['task232_iirc_link_number_classification.json', 1.0, 1], ['task556_alt_translation_en_ja.json', 75.86138613861387, 173], ['task1220_ted_translation_en_ar.json', 65.33663366336634, 432], ['task1164_coda19_section_correction_classification.json', 1.0, 1], ['task248_dream_classification.json', 1.8514851485148516, 3], ['task1253_ted_translation_it_pl.json', 28.613861386138613, 107], ['task873_opus_xhosanavy_translation_xhosa_eng.json', 22.10891089108911, 94], ['task420_persent_document_sentiment_classification.json', 2.485148514851485, 3], ['task691_mmmlu_answer_generation_college_physics.json', 1.0, 1], ['task708_mmmlu_answer_generation_high_school_physics.json', 1.0, 1], ['task918_coqa_answer_generation.json', 9.584158415841584, 124], ['task1308_amazonreview_category_classification.json', 1.0, 1], ['task601_flores_translation_sntoen.json', 22.435643564356436, 46], ['task727_mmmlu_answer_generation_prehistory.json', 1.0, 1], ['task141_odd-man-out_classification_category.json', 1.7425742574257426, 4], ['task449_opus_paracrawl_ig_en_translation.json', 25.544554455445546, 79], ['task559_alt_translation_en_fi.json', 62.277227722772274, 162], ['task495_semeval_headline_classification.json', 2.495049504950495, 3], ['task1725_civil_comments_severtoxicity_classification.json', 1.0, 1], ['task698_mmmlu_answer_generation_global_facts.json', 1.0, 1], ['task1017_pib_translation_hindi_malayalam.json', 161.43564356435644, 573], ['task343_winomt_classification_profession_anti.json', 2.1386138613861387, 5], ['task302_record_classification.json', 3.0, 3], ['task089_swap_words_verification.json', 6.247524752475248, 8], ['task1385_anli_r1_entailment.json', 3.0, 3], ['task704_mmmlu_answer_generation_high_school_government_and_politics.json', 1.0, 1], ['task804_pawsx_german_spanish_translation.json', 34.75247524752475, 57], ['task549_alt_translation_en_vi.json', 94.05940594059406, 236], ['task196_sentiment140_answer_generation.json', 1.0, 1], ['task021_mctaco_grammatical_logical.json', 2.0, 2], ['task1448_disease_entity_extraction_ncbi_dataset.json', 3.891089108910891, 12], ['task1282_ted_translation_pt_fa.json', 89.98019801980197, 344], ['task1102_ted_translation_es_pl.json', 30.544554455445546, 116], ['task488_extract_all_alphabetical_elements_from_list_in_order.json', 13.584158415841584, 31], ['task428_senteval_inversion.json', 1.5643564356435644, 2], ['task597_cuad_answer_generation.json', 84.8019801980198, 304], ['task875_emotion_classification.json', 1.108910891089109, 2], ['task1221_ted_translation_en_he.json', 78.54455445544555, 490], ['task1260_ted_translation_pl_he.json', 73.21782178217822, 392], ['task429_senteval_tense.json', 1.4851485148514851, 2], ['task1086_pib_translation_marathi_english.json', 27.07920792079208, 76], ['task1263_ted_translation_pl_fa.json', 114.99009900990099, 528], ['task441_eng_guj_parallel_corpus_gu-en_language_identification.json', 1.891089108910891, 3], ['task1121_alt_ja_khm_translation.json', 287.029702970297, 642], ['task684_online_privacy_policy_text_information_type_generation.json', 2.8415841584158414, 5], ['task1388_cb_entailment.json', 3.0, 3], ['task1135_xcsr_en_commonsense_mc_classification.json', 1.0, 1], ['task204_mnli_same_genre_classification.json', 1.0, 1], ['task130_scan_structured_text_generation_command_action_long.json', 161.92079207920793, 264], ['task317_crows-pairs_classification_stereotype_type.json', 2.3168316831683167, 5], ['task813_pawsx_japanese_english_translation.json', 29.287128712871286, 46], ['task1424_mathqa_probability.json', 1.0, 1], ['task395_persianqa_answer_generation.json', 45.386138613861384, 137], ['task267_concatenate_and_reverse_all_elements_from_index_i_to_j.json', 16.544554455445546, 69], ['task1233_ted_translation_ar_he.json', 86.43564356435644, 361], ['task958_e2e_nlg_text_generation_parse.json', 35.45544554455446, 55], ['task147_afs_argument_similarity_gay_marriage.json', 1.7326732673267327, 2], ['task697_mmmlu_answer_generation_formal_logic.json', 1.0, 1], ['task537_alt_translation_th_en.json', 32.16831683168317, 84], ['task1367_opustedtalks_translation.json', 21.81188118811881, 99], ['task931_dailydialog_classification.json', 1.0, 1], ['task1024_pib_translation_hindi_english.json', 30.495049504950494, 105], ['task1401_obqa_sentence_generation.json', 11.96039603960396, 28], ['task1549_wiqa_answer_generation_missing_step.json', 7.0, 7], ['task525_parsinlu_movie_aspect_classification.json', 1.2772277227722773, 3], ['task909_dialogre_prevalent_speakers.json', 2.0, 2], ['task1070_pib_translation_urdu_bengali.json', 156.45544554455446, 683], ['task293_storycommonsense_emotion_text_generation.json', 1.801980198019802, 9], ['task365_synthetic_remove_vowels.json', 5.3861386138613865, 13], ['task1515_imppres_longtextgeneration.json', 13.089108910891088, 24], ['task992_pib_translation_tamil_english.json', 24.178217821782177, 77], ['task274_overruling_legal_classification.json', 3.871287128712871, 5], ['task153_tomqa_find_location_hard_clean.json', 4.237623762376238, 7], ['task688_mmmlu_answer_generation_college_computer_science.json', 1.0, 1], ['task730_mmmlu_answer_generation_professional_medicine.json', 1.0, 1], ['task608_sbic_sexual_offense_binary_classification.json', 1.0, 1], ['task110_logic2text_sentence_generation.json', 33.663366336633665, 98], ['task349_squad2.0_answerable_unanswerable_question_classification.json', 1.0, 1], ['task762_emea_fr_sk_translation.json', 41.93069306930693, 167], ['task251_spl_translation_en_fi.json', 23.08910891089109, 41], ['task874_opus_xhosanavy_sr.json', 4.376237623762377, 28], ['task735_mmmlu_answer_generation_us_foreign_policy.json', 1.0, 1], ['task1049_pib_translation_malayalam_telugu.json', 281.76237623762376, 736], ['task522_news_editorial_summary.json', 43.48514851485149, 175], ['task131_scan_long_text_generation_action_command_long.json', 9.316831683168317, 11], ['task566_circa_classification.json', 1.0, 1], ['task485_cls_japanese_books_classification.json', 2.0, 2], ['task1409_dart_text_generation.json', 27.673267326732674, 94], ['task341_winomt_classification_gender_anti.json', 1.4356435643564356, 2], ['task085_unnatural_addsub_arithmetic.json', 5.455445544554456, 6], ['task679_hope_edi_english_text_classification.json', 3.5445544554455446, 4], ['task808_pawsx_chinese_korean_translation.json', 76.25742574257426, 142], ['task858_inquisitive_span_detection.json', 5.079207920792079, 13], ['task1294_wiki_qa_answer_verification.json', 1.0, 1], ['task1353_hind_encorp_translation_en_hi.json', 147.69306930693068, 967], ['task644_refresd_translation.json', 51.198019801980195, 96], ['task1251_ted_translation_it_he.json', 80.93069306930693, 357], ['task399_semeval_2018_task1_tweet_sadness_detection.json', 1.396039603960396, 2], ['task1579_gigaword_incorrect_summarization.json', 13.930693069306932, 33], ['task891_gap_coreference_resolution.json', 2.594059405940594, 7], ['task1022_pib_translation_malayalam_english.json', 27.821782178217823, 82], ['task086_translated_symbol_arithmetic.json', 5.455445544554456, 6], ['task706_mmmlu_answer_generation_high_school_mathematics.json', 1.0, 1], ['task866_mawps_multidiv_question_answering.json', 3.277227722772277, 6], ['task1129_alt_ja_th_answer_generation.json', 1.0, 1], ['task1088_array_of_products.json', 45.94059405940594, 73], ['task065_timetravel_consistent_sentence_classification.json', 3.0, 3], ['task1089_check_monotonic_array.json', 2.0, 2], ['task1211_atomic_classification_hassubevent.json', 1.0, 1], ['task456_matres_intention_classification.json', 1.0, 1], ['task1309_amazonreview_summary_classification.json', 1.0, 1], ['task981_pib_translation_bengali_tamil.json', 151.65346534653466, 343], ['task264_paper_reviews_accept_or_reject_classification.json', 1.0, 1], ['task527_parsinlu_food_overal_classification.json', 1.4752475247524752, 2], ['task665_mmmlu_answer_generation_anatomy.json', 1.0, 1], ['task900_freebase_qa_category_classification.json', 1.198019801980198, 6], ['task1514_flores_translation_entone.json', 89.52475247524752, 157], ['task1356_xlsum_title_generation.json', 14.01980198019802, 25], ['task1452_location_entity_extraction_btc_corpus.json', 3.8217821782178216, 12], ['task554_alt_translation_en_la.json', 390.66336633663366, 952], ['task1031_pib_translation_bengali_telugu.json', 328.6732673267327, 1518], ['task329_gap_classification.json', 1.3465346534653466, 2], ['task450_opus_paracrawl_so_en_translation.json', 51.97029702970297, 219], ['task1678_mathqa_answer_selection.json', 1.0, 1], ['task098_conala_list_intersection.json', 9.198019801980198, 19], ['task1629_copa_hr_classification.json', 1.0, 1], ['task1227_ted_translation_es_ja.json', 44.06930693069307, 210], ['task379_agnews_topic_classification.json', 1.6237623762376239, 4], ['task150_afs_argument_quality_gun_control.json', 1.0, 1], ['task1405_find_median.json', 4.0, 4], ['task760_msr_sqa_long_text_generation.json', 859.0384615384615, 2444], ['task133_winowhy_reason_plausibility_detection.json', 1.495049504950495, 2], ['task864_asdiv_singleop_question_answering.json', 3.3069306930693068, 18], ['task1676_xquad-ca_translation.json', 15.168316831683168, 36], ['task315_europarl_sv-en_language_identification.json', 1.0, 1], ['task1606_ethos_text_classification.json', 2.485148514851485, 3], ['task010_mctaco_answer_generation_event_ordering.json', 5.801980198019802, 14], ['task333_hateeval_classification_hate_en.json', 3.0495049504950495, 4], ['task1414_ajgt_twitter_ar_classification.json', 4.0, 4], ['task1621_menyo20k-mt_en_yo_language_identification.json', 1.9702970297029703, 3], ['task536_alt_translation_vi_en.json', 32.20792079207921, 69], ['task1051_pib_translation_punjabi_urdu.json', 187.36633663366337, 537], ['task480_cls_german_dvd_classification.json', 2.0, 2], ['task1548_wiqa_binary_classification.json', 3.0, 3], ['task823_peixian-rtgender_sentiment_analysis.json', 2.297029702970297, 3], ['task1064_pib_translation_tamil_gujarati.json', 253.62376237623764, 869], ['task1368_healthfact_sentence_generation.json', 19.14851485148515, 91], ['task476_cls_english_books_classification.json', 2.0, 2], ['task844_financial_phrasebank_classification.json', 1.0, 1], ['task1588_tecla_classification.json', 1.5841584158415842, 2], ['task1219_ted_translation_en_es.json', 30.059405940594058, 145], ['task1200_atomic_classification_xeffect.json', 1.0, 1], ['task212_logic2text_classification.json', 1.693069306930693, 3], ['task1144_xcsr_sw_commonsense_mc_classification.json', 1.0, 1], ['task1265_ted_translation_fa_en.json', 22.06930693069307, 95], ['task1142_xcsr_ar_commonsense_mc_classification.json', 1.0, 1], ['task378_reverse_words_of_given_length.json', 14.564356435643564, 24], ['task097_conala_remove_duplicates.json', 9.653465346534654, 18], ['task1199_atomic_classification_xattr.json', 1.0, 1], ['task1572_samsum_summary.json', 27.980198019801982, 80], ['task751_svamp_subtraction_question_answering.json', 2.5544554455445545, 4], ['task1624_disfl_qa_question_yesno_classification.json', 1.0, 1], ['task994_pib_translation_tamil_hindi.json', 115.39603960396039, 347], ['task906_dialogre_identify_names.json', 3.1584158415841586, 11], ['task501_scruples_anecdotes_post_type_verification.json', 1.0, 1], ['task518_emo_different_dialogue_emotions.json', 1.0, 1], ['task125_conala_pair_differences.json', 31.316831683168317, 63], ['task650_opus100_ar_en_translation.json', 49.603960396039604, 3597], ['task999_pib_translation_malayalam_tamil.json', 152.12871287128712, 459], ['task788_pawsx_korean_japanese_translation.json', 55.68316831683168, 99], ['task560_alt_translation_en_entk.json', 33.960396039603964, 100], ['task1207_atomic_classification_atlocation.json', 1.0, 1], ['task028_drop_answer_generation.json', 4.267326732673268, 24], ['task352_coda-19_classification.json', 40.039603960396036, 146], ['task733_mmmlu_answer_generation_security_studies.json', 1.0, 1], ['task664_mmmlu_answer_generation_abstract_algebra.json', 1.0, 1], ['task1442_doqa_movies_isanswerable.json', 1.0, 1], ['task440_eng_guj_parallel_corpus_gu-en_classification.json', 1.0, 1], ['task753_svamp_addition_question_answering.json', 3.4455445544554455, 8], ['task041_qasc_answer_generation.json', 4.336633663366337, 21], ['task326_jigsaw_classification_obscene.json', 3.227722772277228, 4], ['task234_iirc_passage_line_answer_generation.json', 48.524752475247524, 199], ['task107_splash_question_to_sql.json', 51.277227722772274, 143], ['task793_pawsx_french_chinese_translation.json', 47.75247524752475, 99], ['task435_alt_en_ja_translation.json', 74.11881188118812, 208], ['task772_pawsx_french_text_modification.json', 37.00990099009901, 64], ['task250_spl_translation_en_ar.json', 34.37623762376238, 63], ['task550_discofuse_sentence_generation.json', 23.366336633663366, 51], ['task486_cls_japanese_dvd_classification.json', 2.0, 2], ['task1721_civil_comments_obscenity_classification.json', 1.0, 1], ['task959_e2e_nlg_text_generation_identify.json', 3.5346534653465347, 7], ['task320_stereoset_classification_race.json', 3.8613861386138613, 6], ['task013_mctaco_answer_generation_absolute_timepoint.json', 6.851485148514851, 20], ['task254_spl_translation_fi_en.json', 14.099009900990099, 28], ['task1705_ljspeech_classification.json', 1.0, 1], ['task1077_pib_translation_gujarati_oriya.json', 356.26732673267327, 1046], ['task880_schema_guided_dstc8_classification.json', 3.217821782178218, 5], ['task187_snli_entailment_to_contradiction_text_modification.json', 9.653465346534654, 22], ['task1568_propara_classification.json', 4.0, 4], ['task590_amazonfood_summary_correction_classification.json', 1.0, 1], ['task535_alt_translation_ch_en.json', 31.00990099009901, 84], ['task436_alt_ja_en_translation.json', 34.603960396039604, 91], ['task709_mmmlu_answer_generation_high_school_psychology.json', 1.0, 1], ['task1586_scifact_title_generation.json', 27.386138613861387, 56], ['task1003_pib_translation_bengali_malayalam.json', 146.9009900990099, 446], ['task791_pawsx_french_spanish_translation.json', 34.75247524752475, 57], ['task1447_drug_extraction_ade.json', 4.435643564356436, 14], ['task1133_xcsr_nl_commonsense_mc_classification.json', 1.0, 1], ['task1180_xcopa_commonsense_reasoning_tr.json', 2.0, 2], ['task863_asdiv_multiop_question_answering.json', 3.128712871287129, 6], ['task1488_sarcasmdetection_headline_classification.json', 4.841584158415841, 6], ['task271_europarl_translation.json', 12.861386138613861, 34], ['task1205_atomic_classification_isafter.json', 1.0, 1], ['task1434_head_qa_classification.json', 2.267326732673267, 4], ['task418_persent_title_generation.json', 15.96039603960396, 36], ['task507_position_of_all_numerical_elements_in_list.json', 35.91089108910891, 89], ['task1020_pib_translation_telugu_oriya.json', 379.029702970297, 1415], ['task1343_amazon_us_reviews_rating.json', 3.0, 3], ['task561_alt_translation_en_bg.json', 179.45544554455446, 398], ['task1240_ted_translation_gl_es.json', 25.217821782178216, 63], ['task717_mmmlu_answer_generation_logical_fallacies.json', 1.0, 1], ['task1536_daily_dialog_happiness_classification.json', 2.0, 2], ['task756_find_longert_substring_and_return_all_unique_alphabets_in_it.json', 27.059405940594058, 47], ['task647_answer_generation.json', 5.297029702970297, 10], ['task666_mmmlu_answer_generation_astronomy.json', 1.0, 1], ['task903_deceptive_opinion_spam_classification.json', 1.0, 1], ['task151_tomqa_find_location_easy_clean.json', 4.0594059405940595, 7], ['task1010_pib_translation_hindi_bengali.json', 150.59405940594058, 402], ['task1727_wiqa_what_is_the_effect.json', 1.0, 1], ['task318_stereoset_classification_gender.json', 3.8613861386138613, 6], ['task641_esnli_classification.json', 1.0, 1], ['task843_financial_phrasebank_classification.json', 1.0, 1], ['task725_mmmlu_answer_generation_nutrition.json', 1.0, 1], ['task736_mmmlu_answer_generation_virology.json', 1.0, 1], ['task1083_pib_translation_marathi_tamil.json', 146.1980198019802, 390], ['task1714_convai3_sentence_generation.json', 10.118811881188119, 27], ['task091_all_elements_from_index_i_to_j.json', 23.742574257425744, 98], ['task037_qasc_generate_related_fact.json', 14.623762376237623, 42], ['task1030_pib_translation_punjabi_marathi.json', 130.4257425742574, 494], ['task987_pib_translation_english_oriya.json', 548.0891089108911, 2386], ['task1620_menyo20k-mt_yo_en_translation.json', 28.524752475247524, 83], ['task1276_ted_translation_pt_es.json', 24.831683168316832, 95], ['task033_winogrande_answer_generation.json', 1.7227722772277227, 4], ['task020_mctaco_span_based_question.json', 2.0, 2], ['task595_mocha_answer_generation.json', 8.584158415841584, 13], ['task064_all_elements_except_first_i.json', 41.91089108910891, 108], ['task500_scruples_anecdotes_title_generation.json', 12.188118811881187, 27], ['task1131_xcsr_es_commonsense_mc_classification.json', 1.0, 1], ['task1087_two_number_sum.json', 6.237623762376238, 8], ['task638_multi_woz_classification.json', 6.0, 6], ['task478_cls_english_music_classification.json', 2.0, 2], ['task102_commongen_sentence_generation.json', 7.97029702970297, 13], ['task1148_maximum_ascii_value.json', 1.0, 1], ['task1293_kilt_tasks_hotpotqa_question_answering.json', 4.702970297029703, 11], ['task494_review_polarity_answer_generation.json', 1.0, 1], ['task849_pubmedqa_answer_generation.json', 61.62376237623762, 151], ['task113_count_frequency_of_letter.json', 2.00990099009901, 3], ['task1057_pib_translation_english_urdu.json', 176.07920792079207, 638], ['task1489_sarcasmdetection_tweet_classification.json', 4.514851485148514, 6], ['task1431_head_qa_answer_generation.json', 2.0, 2], ['task1062_pib_translation_marathi_bengali.json', 144.59405940594058, 347], ['task1720_civil_comments_toxicity_classification.json', 1.0, 1], ['task911_bianet_translation.json', 56.51485148514851, 759], ['task1111_ted_translation_he_it.json', 33.742574257425744, 161], ['task1183_xcopa_commonsense_cause_effect_vi.json', 1.0, 1], ['task499_extract_and_add_all_numbers_from_list.json', 5.693069306930693, 6], ['task738_perspectrum_classification.json', 1.99009900990099, 3], ['task1270_ted_translation_fa_gl.json', 30.405940594059405, 90], ['task1690_qed_amara_translation.json', 21.92079207920792, 105], ['task076_splash_correcting_sql_mistake.json', 46.603960396039604, 190], ['task673_google_wellformed_query_classification.json', 1.0, 1], ['task854_hippocorpus_classification.json', 2.0, 2], ['task469_mrqa_answer_generation.json', 4.069306930693069, 15], ['task497_extract_all_numbers_from_list_in_order.json', 42.97029702970297, 107], ['task548_alt_translation_en_ch.json', 59.08910891089109, 267], ['task1394_meta_woz_task_classification.json', 6.792079207920792, 14], ['task1334_sqac_answer_generation.json', 14.168316831683168, 61], ['task108_contextualabusedetection_classification.json', 1.0, 1], ['task667_mmmlu_answer_generation_business_ethics.json', 1.0, 1], ['task1002_pib_translation_urdu_gujarati.json', 279.6930693069307, 800], ['task781_pawsx_english_chinese_translation.json', 47.75247524752475, 99], ['task969_xcopa_commonsense_cause_effect_et.json', 1.0, 1], ['task905_hate_speech_offensive_classification.json', 1.0, 1], ['task244_count_elements_in_set_union.json', 2.5445544554455446, 3], ['task096_conala_list_index_subtraction.json', 21.792079207920793, 38], ['task1380_quarel_correct_option_generation.json', 1.0, 1], ['task295_semeval_2020_task4_commonsense_reasoning.json', 1.0, 1], ['task938_copa_hi_commonsense_reasoning.json', 8.0, 8], ['task493_review_polarity_classification.json', 2.0, 2], ['task1506_celebrity_minimal_dob_span.json', 9.386138613861386, 11], ['task1186_nne_hrngo_classification.json', 2.0, 2], ['task731_mmmlu_answer_generation_professional_psychology.json', 1.0, 1], ['task893_gap_fill_the_blank_coreference_resolution.json', 1.0, 1], ['task703_mmmlu_answer_generation_high_school_geography.json', 1.0, 1], ['task1392_superglue_multirc_answer_verification.json', 1.0, 1], ['task833_poem_sentiment_classification.json', 1.0, 1], ['task324_jigsaw_classification_disagree.json', 2.4356435643564356, 3], ['task552_alt_translation_en_bu.json', 284.5049504950495, 800], ['task1074_pib_translation_tamil_oriya.json', 375.96039603960395, 1415], ['task316_crows-pairs_classification_stereotype.json', 4.99009900990099, 6], ['task1556_scitail_passage_generation.json', 19.019801980198018, 40], ['task1181_xcopa_commonsense_cause_effect_tr.json', 1.0, 1], ['task475_yelp_polarity_classification.json', 4.0, 4], ['task1090_ted_translation_en_gl.json', 25.782178217821784, 143], ['task1413_dart_object_identification.json', 4.603960396039604, 55], ['task134_winowhy_reason_generation.json', 15.425742574257425, 59], ['task1703_ljspeech_textmodification.json', 23.415841584158414, 38], ['task1190_add_integer_to_list.json', 94.79207920792079, 99], ['task995_pib_translation_bengali_english.json', 29.673267326732674, 100], ['task1651_opus_books_en-es__translation.json', 44.31683168316832, 151], ['task639_multi_woz_user_utterance_generation.json', 18.485148514851485, 55], ['task206_collatz_conjecture.json', 23.801980198019802, 41], ['task220_rocstories_title_classification.json', 1.0, 1], ['task1177_xcopa_commonsense_cause_effect_ta.json', 1.0, 1], ['task466_parsinlu_qqp_text_modification.json', 42.46534653465346, 134], ['task1292_yelp_review_full_text_categorization.json', 3.0, 3], ['task517_emo_classify_emotion_of_dialogue.json', 1.0, 1], ['task996_pib_translation_english_bengali.json', 142.9009900990099, 366], ['task642_esnli_classification.json', 1.0, 1], ['task272_europarl_translation.json', 21.574257425742573, 62], ['task1731_quartz_question_answering.json', 1.8613861386138615, 13], ['task541_alt_translation_kh_en.json', 35.73267326732673, 104], ['task806_pawsx_german_japanese_translation.json', 55.68316831683168, 99], ['task1573_samsum_classification.json', 1.0, 1], ['task1277_ted_translation_pt_ar.json', 71.72277227722772, 346], ['task699_mmmlu_answer_generation_high_school_biology.json', 1.0, 1], ['task1170_xcopa_commonsense_reasoning_id.json', 2.0, 2], ['task675_google_wellformed_query_sentence_generation.json', 11.168316831683168, 26], ['task1667_cail2018_answer_generation.json', 19.168316831683168, 51], ['task1366_healthfact_classification.json', 2.0, 2], ['task1480_gene_extraction_jnlpba_dataset.json', 5.01980198019802, 10], ['task075_squad1.1_answer_generation.json', 6.257425742574258, 24], ['task624_ohsumed_question_answering.json', 23.376237623762375, 51], ['task591_sciq_answer_generation.json', 2.9405940594059405, 8], ['task1441_doqa_movies_answer_generation.json', 20.495049504950494, 44], ['task463_parsinlu_entailment_classification.json', 3.0, 3], ['task831_giga_fren_classification.json', 1.0, 1], ['task1198_atomic_classification_owant.json', 1.0, 1], ['task1530_scitail1.1_sentence_generation.json', 17.85148514851485, 37], ['task1053_pib_translation_hindi_urdu.json', 131.7029702970297, 454], ['task186_snli_contradiction_to_entailment_text_modification.json', 8.970297029702971, 30], ['task1497_bengali_book_reviews_sentiment_classification.json', 1.0, 1], ['task1654_mkb_translation.json', 96.13861386138613, 318], ['task1433_head_qa_language_translation_es_to_en.json', 12.495049504950495, 28], ['task1500_dstc3_classification.json', 2.6930693069306932, 4], ['task1436_ro_sts_parallel_language_translation_en_to_ro.json', 13.564356435643564, 24], ['task887_quail_answer_generation.json', 4.0, 14], ['task1011_pib_translation_hindi_punjabi.json', 296.4752475247525, 874], ['task898_freebase_qa_answer_generation.json', 4.0495049504950495, 12], ['task231_iirc_link_classification.json', 1.0, 1], ['task1451_drug_dose_extraction.json', 4.574257425742574, 14], ['task100_concatenate_all_elements_from_index_i_to_j.json', 16.683168316831683, 58], ['task523_find_if_numbers_or_alphabets_are_more_in_list.json', 4.3861386138613865, 10], ['task646_answer_generation.json', 2.405940594059406, 7], ['task229_arc_answer_generation_hard.json', 1.0, 1], ['task276_enhanced_wsc_classification.json', 1.900990099009901, 2], ['task116_com2sense_commonsense_reasoning.json', 1.0, 1], ['task200_mnli_entailment_classification.json', 2.0, 2], ['task149_afs_argument_quality_death_penalty.json', 1.0, 1], ['task1453_person_entity_extraction_btc_corpus.json', 3.9603960396039604, 14], ['task184_snli_entailment_to_neutral_text_modification.json', 10.069306930693068, 38], ['task361_spolin_yesand_prompt_response_classification.json', 1.0, 1], ['task1134_xcsr_hi_commonsense_mc_classification.json', 1.0, 1], ['task1648_opus_books_en-sv_translation.json', 31.178217821782177, 131], ['task066_timetravel_binary_consistency_classification.json', 1.0, 1], ['task047_miscellaneous_answering_science_questions.json', 2.0, 2], ['task160_replace_letter_in_a_sentence.json', 16.326732673267326, 31], ['task1040_pib_translation_punjabi_oriya.json', 516.6732673267327, 2276], ['task654_bible_fa_en_translation.json', 34.198019801980195, 68], ['task1061_pib_translation_bengali_marathi.json', 113.13861386138613, 438], ['task878_kde4_translation.json', 95.15841584158416, 223], ['task776_pawsx_japanese_text_modification.json', 55.68316831683168, 99], ['task555_alt_translation_en_kh.json', 297.6930693069307, 805], ['task1210_atomic_classification_madeupof.json', 1.0, 1], ['task1284_hrngo_informativeness_classification.json', 2.0, 2], ['task1619_menyo20k-mt_en_yo_translation.json', 77.5940594059406, 463], ['task838_cdt_classification.json', 2.0, 2], ['task1132_xcsr_ur_commonsense_mc_classification.json', 1.0, 1], ['task1350_opus100_translation_en_gu.json', 236.41584158415841, 841], ['task1390_wscfixed_coreference.json', 1.0, 1], ['task145_afs_argument_similarity_death_penalty.json', 1.5940594059405941, 2], ['task975_prachathai67k_same_genre_classification.json', 1.0, 1], ['task332_tellmewhy_answer_generation.json', 9.297029702970297, 24], ['task1173_xcopa_commonsense_cause_effect_it.json', 1.0, 1], ['task511_reddit_tifu_long_text_summarization.json', 28.89108910891089, 136], ['task228_arc_answer_generation_easy.json', 1.0, 1], ['task861_asdiv_addsub_question_answering.json', 3.0396039603960396, 8], ['task181_outcome_extraction.json', 4.227722772277228, 27], ['task334_hateeval_classification_hate_es.json', 2.9504950495049505, 4], ['task635_allegro_reviews_answer_generation.json', 1.0, 1], ['task734_mmmlu_answer_generation_sociology.json', 1.0, 1], ['task073_commonsenseqa_answer_generation.json', 1.0, 1], ['task632_dbpedia_14_classification.json', 1.0, 1], ['task957_e2e_nlg_text_generation_generate.json', 27.396039603960396, 53], ['task087_new_operator_addsub_arithmetic.json', 5.435643564356436, 6], ['task1097_ted_translation_ja_pl.json', 35.79207920792079, 120], ['task360_spolin_yesand_response_generation.json', 23.831683168316832, 77], ['task683_online_privacy_policy_text_purpose_answer_generation.json', 3.3267326732673266, 5], ['task322_jigsaw_classification_threat.json', 3.891089108910891, 5], ['task1223_ted_translation_ja_es.json', 28.247524752475247, 139], ['task1161_coda19_title_generation.json', 30.396039603960396, 80], ['task687_mmmlu_answer_generation_college_chemistry.json', 1.0, 1], ['task818_pawsx_japanese_chinese_translation.json', 47.75247524752475, 99], ['task1661_super_glue_classification.json', 2.0, 2], ['task912_bianet_classification.json', 1.0198019801980198, 3], ['task190_snli_classification.json', 1.0, 1], ['task143_odd-man-out_classification_generate_category.json', 2.227722772277228, 5], ['task1122_alt_khm_ja_translation.json', 74.11881188118812, 208], ['task177_para-nmt_paraphrasing.json', 16.455445544554454, 37], ['task396_persianqa_classification.json', 1.0, 1], ['task266_paper_reviews_reviewer_perspective_classification.json', 1.4752475247524752, 2], ['task1204_atomic_classification_hinderedby.json', 1.0, 1], ['task685_mmmlu_answer_generation_clinical_knowledge.json', 1.0, 1], ['task1508_wordnet_antonyms.json', 2.792079207920792, 6], ['task600_find_the_longest_common_substring_in_two_strings.json', 4.801980198019802, 10], ['task1038_pib_translation_urdu_telugu.json', 312.61386138613864, 994], ['task520_aquamuse_answer_given_in_passage.json', 1.0, 1], ['task1047_pib_translation_english_telugu.json', 290.16831683168317, 835], ['task427_hindienglish_corpora_hi-en_language_identification.json', 1.4653465346534653, 2], ['task1197_atomic_classification_oreact.json', 1.0, 1], ['task118_semeval_2019_task10_open_vocabulary_mathematical_answer_generation.json', 1.0, 1], ['task199_mnli_classification.json', 1.0, 1], ['task1029_pib_translation_marathi_punjabi.json', 308.3069306930693, 1074], ['task1435_ro_sts_parallel_language_translation_ro_to_en.json', 8.990099009900991, 17], ['task252_spl_translation_en_tr.json', 25.02970297029703, 45], ['task545_alt_translation_fi_en.json', 32.722772277227726, 89], ['task722_mmmlu_answer_generation_random_topic.json', 1.0, 1], ['task1055_pib_translation_marathi_oriya.json', 387.44554455445547, 1411], ['task998_pib_translation_oriya_bengali.json', 159.69306930693068, 454], ['task877_kde4_translation.json', 53.633663366336634, 369], ['task1258_ted_translation_pl_es.json', 26.376237623762375, 92], ['task1545_conll2002_person_name_extraction_answer_generation.json', 5.900990099009901, 35], ['task526_parsinlu_movie_overal_classification.json', 1.0, 1], ['task1196_atomic_classification_oeffect.json', 1.0, 1], ['task1625_disfl_qa_asnwer_generation.json', 2.6633663366336635, 13], ['task610_conllpp_ner.json', 42.76237623762376, 115], ['task540_alt_translation_la_en.json', 33.396039603960396, 75], ['task438_eng_guj_parallel_corpus_en_gu_translation.json', 178.6138613861386, 303], ['task1109_ted_translation_ar_pt.json', 29.297029702970296, 146], ['task978_pib_translation_urdu_oriya.json', 671.3069306930693, 2219], ['task888_reviews_classification.json', 1.0, 1], ['task553_alt_translation_en_ma.json', 61.801980198019805, 161], ['task721_mmmlu_answer_generation_medical_genetics.json', 1.0, 1], ['task016_mctaco_answer_generation_frequency.json', 3.900990099009901, 13], ['task582_naturalquestion_answer_generation.json', 4.7227722772277225, 10], ['task1246_ted_translation_gl_pt.json', 26.722772277227723, 93], ['task1647_opus_books_en-pt_translation.json', 40.00990099009901, 166], ['task1599_smcalflow_classification.json', 1.0, 1], ['task1499_dstc3_summarization.json', 32.336633663366335, 40], ['task327_jigsaw_classification_toxic.json', 3.00990099009901, 4], ['task1509_evalution_antonyms.json', 1.4158415841584158, 4], ['task742_lhoestq_answer_generation_frequency.json', 3.118811881188119, 22], ['task126_scan_structured_text_generation_command_action_all.json', 76.99009900990099, 192], ['task1107_ted_translation_ar_pl.json', 33.64356435643565, 156], ['task1608_xquad_en_answer_generation.json', 3.5445544554455446, 11], ['task774_pawsx_german_text_modification.json', 33.78217821782178, 53], ['task1544_conll2002_named_entity_recognition_answer_generation.json', 12.732673267326733, 80], ['task1274_ted_translation_pt_en.json', 18.762376237623762, 56], ['task1212_atomic_classification_hasproperty.json', 1.0, 1], ['task662_global_voices_fa_en_translation.json', 28.18811881188119, 119], ['task1554_scitail_classification.json', 1.495049504950495, 2], ['task158_count_frequency_of_words.json', 2.0, 2], ['task747_glucose_cause_emotion_detection.json', 20.782178217821784, 30], ['task1232_ted_translation_ar_es.json', 27.14851485148515, 99], ['task1289_trec_classification.json', 1.2277227722772277, 3], ['task1162_coda19_title_classification.json', 1.0, 1], ['task1341_msr_text_classification.json', 1.0, 1], ['task223_quartz_explanation_generation.json', 20.386138613861387, 44], ['task1150_delete_max_min.json', 87.4059405940594, 90], ['task505_count_all_numerical_elements_in_list.json', 2.5841584158415842, 3], ['task1228_ted_translation_es_ar.json', 67.93069306930693, 233], ['task1001_pib_translation_gujarati_urdu.json', 127.68316831683168, 421], ['task547_alt_translation_entk_en.json', 33.32673267326733, 98], ['task1336_peixian_equity_evaluation_corpus_gender_classifier.json', 1.0, 1], ['task1004_pib_translation_malayalam_bengali.json', 122.79207920792079, 501], ['task093_conala_normalize_lists.json', 38.02970297029703, 62], ['task1230_ted_translation_ar_en.json', 22.534653465346533, 202], ['task1139_xcsr_ru_commonsense_mc_classification.json', 1.0, 1], ['task993_pib_translation_hindi_tamil.json', 149.30693069306932, 457], ['task764_emea_bg_el_classification.json', 1.0, 1], ['task1021_pib_translation_english_malayalam.json', 143.27722772277227, 428], ['task178_quartz_question_answering.json', 1.8217821782178218, 13], ['task104_semeval_2019_task10_closed_vocabulary_mathematical_answer_generation.json', 1.0, 1], ['task1640_aqa1.0_answerable_unanswerable_question_classification.json', 1.0, 1], ['task1338_peixian_equity_evaluation_corpus_sentiment_classifier.json', 1.2475247524752475, 2], ['task1404_date_conversion.json', 11.0, 11], ['task146_afs_argument_similarity_gun_control.json', 1.8316831683168318, 2], ['task1692_qed_amara_translation.json', 20.128712871287128, 115], ['task1209_atomic_classification_objectuse.json', 1.0, 1], ['task872_opus_xhosanavy_translation_eng_xhosa.json', 41.64356435643565, 146], ['task1406_kth_smallest_element.json', 3.633663366336634, 4], ['task716_mmmlu_answer_generation_jurisprudence.json', 1.0, 1], ['task1291_multi_news_summarization.json', 319.23762376237624, 492], ['task1369_healthfact_sentence_generation.json', 77.13861386138613, 440], ['task423_persent_document_sentiment_verification.json', 1.0, 1], ['task464_parsinlu_entailment_sentence_generation.json', 56.98019801980198, 174], ['task580_socialiqa_answer_generation.json', 1.0, 1], ['task506_position_of_all_alphabetical_elements_in_list.json', 37.306930693069305, 90], ['task174_spl_translation_en_ja.json', 23.782178217821784, 41], ['task452_opus_paracrawl_en_ig_translation.json', 50.13861386138614, 248], ['task018_mctaco_temporal_reasoning_presence.json', 2.0, 2], ['task1226_ted_translation_es_en.json', 25.257425742574256, 127], ['task546_alt_translation_bg_en.json', 32.9009900990099, 86], ['task1052_pib_translation_urdu_punjabi.json', 381.84158415841586, 1274], ['task565_circa_answer_generation.json', 7.821782178217822, 16], ['task1179_xcopa_commonsense_cause_effect_th.json', 1.0, 1], ['task1331_reverse_array.json', 93.52475247524752, 100], ['task1218_ted_translation_en_ja.json', 43.76237623762376, 164], ['task1626_copa_hr_question_answering.json', 11.792079207920793, 27], ['task718_mmmlu_answer_generation_machine_learning.json', 1.0, 1], ['task210_logic2text_structured_text_generation.json', 29.326732673267326, 64], ['task1125_alt_lo_ja_translation.json', 72.89108910891089, 165], ['task083_babi_t1_single_supporting_fact_answer_generation.json', 1.5148514851485149, 2], ['task1532_daily_dialog_emotion_classification.json', 30.742574257425744, 71], ['task109_smsspamcollection_spamsmsdetection.json', 1.2277227722772277, 2], ['task319_stereoset_classification_profession.json', 3.8613861386138613, 6], ['task1027_pib_translation_marathi_telugu.json', 269.8910891089109, 939], ['task157_count_vowels_and_consonants.json', 3.0, 3], ['task1028_pib_translation_telugu_marathi.json', 111.52475247524752, 344], ['task1091_ted_translation_en_it.json', 30.77227722772277, 114], ['task263_spl_translation_pl_en.json', 14.03960396039604, 28], ['task622_replace_alphabets_in_a_list_by_their_position_in_english_alphabet.json', 98.13861386138613, 194], ['task1355_sent_comp_summarization.json', 15.297029702970297, 30], ['task447_opus_paracrawl_classification.json', 1.396039603960396, 2], ['task019_mctaco_temporal_reasoning_category.json', 2.0, 2], ['task1110_ted_translation_he_gl.json', 32.306930693069305, 184], ['task1395_europa_ecdc_tm_en_sv_translation.json', 34.415841584158414, 150], ['task780_pawsx_english_german_translation.json', 33.78217821782178, 53], ['task205_remove_even_elements.json', 12.514851485148515, 27], ['task487_cls_japanese_music_classification.json', 2.0, 2], ['task291_semeval_2020_task4_commonsense_validation.json', 1.0, 1], ['task077_splash_explanation_to_sql.json', 43.277227722772274, 104], ['task1577_amazon_reviews_multi_japanese_language_classification.json', 3.01980198019802, 5], ['task653_parsinlu_fa_en_translation.json', 16.06930693069307, 42], ['task700_mmmlu_answer_generation_high_school_chemistry.json', 1.0, 1], ['task655_bible_en_fa_translation.json', 96.79207920792079, 227], ['task1516_imppres_naturallanguageinference.json', 1.3267326732673268, 2], ['task1658_billsum_summarization.json', 265.5247524752475, 914], ['task1517_limit_classfication.json', 1.0, 1], ['task1449_disease_entity_extraction_bc5cdr_dataset.json', 4.441558441558442, 11], ['task1342_amazon_us_reviews_title.json', 6.772277227722772, 28], ['task1101_ted_translation_es_it.json', 29.584158415841586, 107], ['task765_emea_bg_el_translation.json', 130.56435643564356, 476], ['task713_mmmlu_answer_generation_human_aging.json', 1.0, 1], ['task1553_cnn_dailymail_summarization.json', 71.2871287128713, 113], ['task509_collate_of_all_alphabetical_and_numerical_elements_in_list_separately.json', 79.62376237623762, 173], ['task1041_pib_translation_gujarati_malayalam.json', 164.95049504950495, 479], ['task778_pawsx_english_french_translation.json', 37.00990099009901, 64], ['task1329_open_subtitles_en_hi_translation.json', 22.97029702970297, 66], ['task1151_swap_max_min.json', 96.55445544554455, 100], ['task768_qed_text_span_selection.json', 3.3465346534653464, 6], ['task1296_wiki_hop_question_answering.json', 3.3564356435643563, 17], ['task233_iirc_link_exists_classification.json', 1.0, 1], ['task1408_dart_similarity_classification.json', 4.0, 4], ['task194_duorc_answer_generation.json', 6.633663366336633, 20], ['task1328_qa_zre_relation_generation_from_question.json', 2.0594059405940595, 3], ['task775_pawsx_chinese_text_modification.json', 47.75247524752475, 99], ['task439_eng_guj_parallel_corpus_gu_en_translation.json', 19.722772277227723, 36], ['task1312_amazonreview_polarity_classification.json', 1.0, 1], ['task851_synthetic_multiply_evens.json', 42.97029702970297, 79], ['task127_scan_long_text_generation_action_command_all.json', 7.9405940594059405, 11], ['task1652_opus_books_ca-en_translation.json', 44.31683168316832, 151], ['task604_flores_translation_entosn.json', 146.4851485148515, 290], ['task627_xlwic_word_with_same_meaning_sentence_generation.json', 10.841584158415841, 29], ['task1610_xquad_es_answer_generation.json', 4.0594059405940595, 24], ['task710_mmmlu_answer_generation_high_school_statistics.json', 1.0, 1], ['task482_cls_french_books_classification.json', 2.0, 2], ['task723_mmmlu_answer_generation_moral_disputes.json', 1.0, 1], ['task982_pib_translation_tamil_bengali.json', 128.65346534653466, 306], ['task364_regard_social_impact_classification.json', 2.0, 2], ['task1243_ted_translation_gl_it.json', 26.73267326732673, 122], ['task372_synthetic_palindrome_numbers.json', 10.326732673267326, 32], ['task532_europarl_en-es_classification.json', 1.0, 1], ['task1540_parsed_pdfs_summarization.json', 15.841584158415841, 31], ['task557_alt_translation_en_ba.json', 55.34653465346535, 128], ['task827_copa_commonsense_reasoning.json', 2.0, 2], ['task424_hindienglish_corpora_hi_en_translation.json', 36.16831683168317, 127], ['task207_max_element_lists.json', 21.92079207920792, 37], ['task1361_movierationales_classification.json', 1.0, 1], ['task1118_alt_ja_fil_translation.json', 62.16831683168317, 179], ['task538_alt_translation_bu_en.json', 33.78217821782178, 88], ['task217_rocstories_ordering_answer_generation.json', 6.0, 6], ['task1068_pib_translation_gujarati_bengali.json', 139.56435643564356, 456], ['task432_alt_en_hi_translation.json', 147.1881188118812, 341], ['task1006_pib_translation_punjabi_malayalam.json', 166.92079207920793, 623], ['task1445_closest_integers.json', 2.237623762376238, 3], ['task832_poleval2019_mt_classification.json', 1.0, 1], ['task1416_youtube_caption_corrections_incorrect_grammar_classification.json', 641.7920792079208, 689], ['task1215_atomic_classification_capableof.json', 1.0, 1], ['task892_gap_reverse_coreference_resolution.json', 1.0, 1], ['task865_mawps_addsub_question_answering.json', 3.6831683168316833, 19], ['task300_storycloze_order_generation.json', 6.0, 6], ['task462_qasper_classification.json', 2.5742574257425743, 3], ['task612_yorubabbc_classification.json', 1.5742574257425743, 2], ['task544_alt_translation_hi_en.json', 33.05940594059406, 72], ['task101_reverse_and_concatenate_all_elements_from_index_i_to_j.json', 14.881188118811881, 58], ['task609_sbic_potentially_offense_binary_classification.json', 1.0, 1], ['task530_europarl_en_es_translation.json', 45.68316831683168, 178], ['task1616_cc_alligned_translate_eng_tel.json', 157.16831683168317, 1036], ['task1432_head_qa_language_translation_en_to_es.json', 19.801980198019802, 48], ['task1722_civil_comments_threat_classification.json', 1.0, 1], ['task1079_pib_translation_english_gujarati.json', 263.74257425742576, 609], ['task1045_pib_translation_hindi_telugu.json', 320.7722772277228, 878], ['task593_sciq_explanation_generation.json', 27.574257425742573, 57], ['task937_defeasible_nli_social_classification.json', 2.0, 2], ['task162_count_words_starting_with_letter.json', 2.0, 2], ['task1066_pib_translation_telugu_punjabi.json', 274.8217821782178, 1248], ['task390_torque_text_span_selection.json', 0.9207920792079208, 4], ['task1163_coda19_section_classification.json', 1.0, 1], ['task1264_ted_translation_pl_pt.json', 27.336633663366335, 102], ['task056_multirc_classify_correct_answer.json', 2.0, 2], ['task1429_evalution_semantic_relation_classification.json', 2.0, 2], ['task1081_pib_translation_hindi_marathi.json', 119.02970297029702, 344], ['task625_xlwic_true_or_false_answer_generation.json', 2.0, 2], ['task335_hateeval_classification_aggresive_en.json', 4.089108910891089, 5], ['task815_pawsx_japanese_french_translation.json', 37.00990099009901, 64], ['task027_drop_answer_type_generation.json', 1.0, 1], ['task989_pib_translation_marathi_urdu.json', 112.21782178217822, 308], ['task783_pawsx_korean_english_translation.json', 29.287128712871286, 46], ['task218_rocstories_swap_order_answer_generation.json', 3.0, 3], ['task1037_pib_translation_telugu_urdu.json', 111.4059405940594, 389], ['task1008_pib_translation_punjabi_english.json', 40.21782178217822, 172], ['task1650_opus_books_en-fi_translation.json', 36.82178217821782, 176], ['task437_alt_en_ja_answer_generation.json', 1.0, 1], ['task1604_ethos_text_classification.json', 1.5742574257425743, 2], ['task1689_qed_amara_translation.json', 26.99009900990099, 113], ['task529_parsinlu_food_aspect_detection.json', 6.217821782178218, 11], ['task661_mizan_en_fa_translation.json', 81.70297029702971, 180], ['task1278_ted_translation_pt_he.json', 66.1980198019802, 309], ['task1600_smcalflow_sentence_generation.json', 10.475247524752476, 30], ['task1048_pib_translation_telugu_english.json', 30.326732673267326, 88], ['task063_first_i_elements.json', 14.316831683168317, 51], ['task1178_xcopa_commonsense_reasoning_th.json', 2.0, 2], ['task966_ruletaker_fact_checking_based_on_given_context.json', 1.0, 1], ['task1000_pib_translation_tamil_malayalam.json', 152.009900990099, 401], ['task1176_xcopa_commonsense_reasoning_ta.json', 2.0, 2], ['task576_curiosity_dialogs_answer_generation.json', 35.32673267326733, 119], ['task1106_ted_translation_ar_it.json', 27.712871287128714, 96], ['task862_asdiv_multidiv_question_answering.json', 4.574257425742574, 19], ['task750_aqua_multiple_choice_answering.json', 2.0, 2], ['task1487_organism_substance_extraction_anem_dataset.json', 1.5346534653465347, 4], ['task148_afs_argument_quality_gay_marriage.json', 1.0, 1], ['task129_scan_long_text_generation_action_command_short.json', 7.564356435643564, 11], ['task611_mutual_multi_turn_dialogue.json', 1.0, 1], ['task598_cuad_answer_generation.json', 5.712871287128713, 7], ['task245_check_presence_in_set_intersection.json', 1.0, 1], ['task979_pib_translation_malayalam_oriya.json', 321.2772277227723, 1135], ['task444_com_qa_question_paraphrases_answer_generation.json', 7.871287128712871, 47], ['task1175_xcopa_commonsense_cause_effect_sw.json', 1.0, 1], ['task1269_ted_translation_fa_he.json', 75.5940594059406, 388], ['task1259_ted_translation_pl_ar.json', 74.22772277227723, 266], ['task260_spl_translation_zh_en.json', 14.05940594059406, 28], ['task839_cdt_classification.json', 1.0, 1], ['task1013_pib_translation_gujarati_telugu.json', 319.2475247524753, 885], ['task814_pawsx_japanese_korean_translation.json', 76.25742574257426, 142], ['task829_giga_fren_translation.json', 25.178217821782177, 87], ['task388_torque_token_classification.json', 1.3267326732673268, 4], ['task936_defeasible_nli_snli_classification.json', 2.0, 2], ['task1206_atomic_classification_isbefore.json', 1.0, 1], ['task479_cls_german_books_classification.json', 2.0, 2], ['task1358_xlsum_title_generation.json', 13.970297029702971, 22], ['task1245_ted_translation_gl_fa.json', 97.56435643564356, 390], ['task137_detoxifying-lms_classification_toxicity.json', 3.0, 3], ['task1072_pib_translation_marathi_malayalam.json', 147.79207920792078, 337], ['task1501_dstc3_answer_generation.json', 1.0, 1], ['task930_dailydialog_classification.json', 1.0, 1], ['task720_mmmlu_answer_generation_marketing.json', 1.0, 1], ['task1138_xcsr_de_commonsense_mc_classification.json', 1.0, 1], ['task790_pawsx_french_korean_translation.json', 76.25742574257426, 142], ['task1272_ted_translation_fa_pl.json', 39.35643564356435, 268], ['task812_pawsx_chinese_japanese_translation.json', 55.68316831683168, 99], ['task1015_pib_translation_punjabi_tamil.json', 159.13861386138615, 598], ['task1310_amazonreview_rating_classification.json', 2.0, 2], ['task088_identify_typo_verification.json', 2.504950495049505, 5], ['task114_is_the_given_word_longest.json', 1.0, 1], ['task850_synthetic_longest_palindrome.json', 3.603960396039604, 9], ['task910_bianet_classification.json', 1.0, 1], ['task288_gigaword_summarization.json', 15.158415841584159, 33], ['task589_amazonfood_summary_text_generation.json', 7.297029702970297, 32], ['task465_parsinlu_qqp_classification.json', 5.3861386138613865, 6], ['task188_snli_neutral_to_entailment_text_modification.json', 8.07920792079208, 17], ['task431_senteval_object_count.json', 2.0, 2], ['task159_check_frequency_of_words_in_sentence_pair.json', 1.0, 1], ['task1534_daily_dialog_question_classification.json', 2.0, 2], ['task711_mmmlu_answer_generation_high_school_us_history.json', 1.0, 1], ['task663_global_voices_en_fa_translation.json', 106.16831683168317, 293], ['task578_curiosity_dialogs_answer_generation.json', 2.9306930693069306, 8], ['task652_parsinlu_en_fa_translation.json', 62.26732673267327, 172], ['task816_pawsx_japanese_spanish_translation.json', 34.75247524752475, 57], ['task237_iirc_answer_from_subtext_answer_generation.json', 6.128712871287129, 35], ['task255_spl_translation_it_en.json', 14.069306930693068, 28], ['task693_mmmlu_answer_generation_conceptual_physics.json', 1.0, 1], ['task362_spolin_yesand_prompt_response_sub_classification.json', 3.0, 3], ['task630_dbpedia_14_classification.json', 1.0, 1], ['task330_gap_answer_generation.json', 2.99009900990099, 11], ['task1411_dart_subject_identification.json', 4.683168316831683, 40], ['task1194_kth_largest_element.json', 3.6732673267326734, 4], ['task677_ollie_sentence_answer_generation.json', 31.752475247524753, 90], ['task1410_dart_relationship_extraction.json', 60.554455445544555, 144], ['task1484_gene_extraction_linnaeus_dataset.json', 5.564356435643564, 9], ['task1071_pib_translation_malayalam_marathi.json', 109.63366336633663, 366], ['task197_mnli_domain_answer_generation.json', 1.4455445544554455, 2], ['task1529_scitail1.1_classification.json', 1.495049504950495, 2], ['task1613_sick_given_category_generate_sentence.json', 11.386138613861386, 25], ['task1174_xcopa_commonsense_reasoning_sw.json', 2.0, 2], ['task1234_ted_translation_he_en.json', 26.08910891089109, 152], ['task039_qasc_find_overlapping_words.json', 1.9108910891089108, 5], ['task1315_find_range_array.json', 4.0, 4], ['task243_count_elements_in_set_intersection.json', 2.0, 2], ['task1407_dart_question_generation.json', 27.792079207920793, 72], ['task606_sum_of_all_numbers_in_list_between_positions_i_and_j.json', 5.207920792079208, 6], ['task1520_qa_srl_answer_generation.json', 7.217821782178218, 46], ['task203_mnli_sentence_generation.json', 15.029702970297029, 48], ['task367_synthetic_remove_floats.json', 9.950495049504951, 27], ['task837_viquiquad_answer_generation.json', 8.297029702970297, 30], ['task577_curiosity_dialogs_classification.json', 1.0, 1], ['task1267_ted_translation_fa_es.json', 29.455445544554454, 120], ['task835_mathdataset_answer_generation.json', 4.326732673267327, 17], ['task1036_pib_translation_urdu_tamil.json', 163.62376237623764, 487], ['task1143_xcsr_it_commonsense_mc_classification.json', 1.0, 1], ['task1582_bless_hypernym_generation.json', 1.5643564356435644, 4], ['task1100_ted_translation_es_gl.json', 26.15841584158416, 64], ['task970_sherliic_causal_relationship.json', 1.0, 1], ['task1375_newscomm_translation.json', 60.396039603960396, 145], ['task400_paws_paraphrase_classification.json', 4.6138613861386135, 5], ['task737_mmmlu_answer_generation_world_religions.json', 1.0, 1], ['task202_mnli_contradiction_classification.json', 2.0, 2], ['task230_iirc_passage_classification.json', 2.0, 2], ['task477_cls_english_dvd_classification.json', 2.0, 2], ['task672_amazon_and_yelp_summarization_dataset_summarization.json', 68.18811881188118, 116], ['task1491_bengali_political_hate_speech_binary_classification.json', 3.5247524752475248, 4], ['task607_sbic_intentional_offense_binary_classification.json', 1.0, 1], ['task743_eurlex_summarization.json', 30.504950495049506, 100], ['task1231_ted_translation_ar_ja.json', 44.64356435643565, 140], ['task1084_pib_translation_tamil_marathi.json', 118.03960396039604, 413], ['task1116_alt_id_ja_translation.json', 75.82178217821782, 303], ['task840_para_pdt_en_es_translation.json', 21.574257425742573, 40], ['task668_extreme_abstract_summarization.json', 25.534653465346533, 59], ['task1485_organ_extraction_anem_dataset.json', 2.198019801980198, 5], ['task1119_alt_fil_ja_translation.json', 75.82178217821782, 303], ['task403_creak_commonsense_inference.json', 1.0, 1], ['task1172_xcopa_commonsense_reasoning_it.json', 2.0, 2], ['task179_participant_extraction.json', 3.900990099009901, 21], ['task1539_kannada_offenseval_dravidian_classification.json', 2.4356435643564356, 3], ['task732_mmmlu_answer_generation_public_relations.json', 1.0, 1], ['task674_google_wellformed_query_sentence_generation.json', 10.445544554455445, 22], ['task1496_bengali_reviews_sentiment_classification.json', 1.0, 1], ['task802_pawsx_german_korean_translation.json', 76.25742574257426, 142], ['task123_conala_sort_dictionary.json', 89.26732673267327, 143], ['task558_alt_translation_en_hi.json', 159.13861386138615, 371], ['task1541_agnews_classification.json', 2.0, 2], ['task386_semeval_2018_task3_irony_detection.json', 1.4554455445544554, 2], ['task658_tep_en_fa_translation.json', 32.92079207920792, 101], ['task766_craigslist_bargains_classification.json', 1.0, 1], ['task323_jigsaw_classification_sexually_explicit.json', 6.0495049504950495, 7], ['task596_mocha_question_generation.json', 12.534653465346535, 24], ['task564_discofuse_classification.json', 8.772277227722773, 15], ['task1023_pib_translation_english_hindi.json', 123.4059405940594, 399], ['task811_pawsx_chinese_german_translation.json', 33.78217821782178, 53], ['task842_para_pdt_cs_en_translation.json', 174.72277227722773, 419], ['task142_odd-man-out_classification_no_category.json', 1.7821782178217822, 4], ['task1443_string_to_number.json', 9.267326732673267, 13], ['task563_discofuse_answer_generation.json', 1.316831683168317, 3], ['task1422_mathqa_physics.json', 1.0, 1], ['task498_scruples_anecdotes_whoiswrong_classification.json', 4.0, 6], ['task890_gcwd_classification.json', 1.6732673267326732, 2], ['task980_pib_translation_oriya_malayalam.json', 136.96039603960395, 392], ['task175_spl_translation_en_pl.json', 22.297029702970296, 47], ['task1316_remove_duplicates_string.json', 15.633663366336634, 22], ['task007_mctaco_answer_generation_transient_stationary.json', 2.762376237623762, 15], ['task351_winomt_classification_gender_identifiability_anti.json', 2.5247524752475248, 3], ['task457_matres_conditional_classification.json', 1.0, 1], ['task152_tomqa_find_location_easy_noise.json', 4.247524752475248, 7], ['task1419_mathqa_gain.json', 1.0, 1], ['task935_defeasible_nli_atomic_classification.json', 2.0, 2], ['task707_mmmlu_answer_generation_high_school_microeconomics.json', 1.0, 1], ['task1078_pib_translation_oriya_gujarati.json', 304.7722772277228, 747], ['task1726_mathqa_correct_answer_generation.json', 5.03960396039604, 30], ['task099_reverse_elements_between_index_i_and_j.json', 25.504950495049506, 89], ['task1222_ted_translation_ja_en.json', 22.940594059405942, 99], ['task044_essential_terms_identifying_essential_words.json', 10.742574257425742, 26], ['task616_cola_classification.json', 1.9108910891089108, 3], ['task1486_cell_extraction_anem_dataset.json', 2.6831683168316833, 10], ['task062_bigbench_repeat_copy_logic.json', 18.93103448275862, 35], ['task265_paper_reviews_language_identification.json', 1.0, 1], ['task1685_menyo20k_translation.json', 68.89108910891089, 243], ['task1575_amazon_reviews_multi_sentiment_classification.json', 1.0, 1], ['task1202_atomic_classification_xneed.json', 1.0, 1], ['task1354_sent_comp_classification.json', 1.0, 1], ['task1691_qed_amara_translation.json', 20.871287128712872, 81], ['task195_sentiment140_classification.json', 1.0, 1], ['task022_cosmosqa_passage_inappropriate_binary.json', 2.0, 2], ['task990_pib_translation_urdu_marathi.json', 115.5940594059406, 394], ['task004_mctaco_answer_generation_event_duration.json', 4.782178217821782, 19], ['task1279_ted_translation_pt_gl.json', 25.00990099009901, 82], ['task1666_cail2018_answer_generation.json', 6.9504950495049505, 10], ['task446_opus_paracrawl_en_so_translation.json', 93.53465346534654, 359], ['task820_protoqa_answer_generation.json', 2.5643564356435644, 8], ['task1039_pib_translation_oriya_punjabi.json', 505.65346534653463, 1876], ['task1067_pib_translation_bengali_gujarati.json', 256.1188118811881, 768], ['task049_multirc_questions_needed_to_answer.json', 7.366336633663367, 31], ['task286_olid_offense_judgment.json', 2.1485148514851486, 5], ['task1340_msr_text_compression_compression.json', 31.861386138613863, 67], ['task1505_root09_semantic_relation_classification.json', 2.792079207920792, 3], ['task1095_ted_translation_ja_gl.json', 24.89108910891089, 117], ['task770_pawsx_english_text_modification.json', 29.287128712871286, 46], ['task1182_xcopa_commonsense_reasoning_vi.json', 2.0, 2], ['task531_europarl_es_en_translation.json', 32.56435643564357, 124], ['task939_copa_hi_commonsense_cause_effect.json', 1.0, 1], ['task942_copa_mr_commonsense_reasoning.json', 8.0, 8], ['task551_alt_translation_en_th.json', 129.30693069306932, 348], ['task1384_deal_or_no_dialog_classification.json', 1.0, 1], ['task051_multirc_correct_answer_single_sentence.json', 5.841584158415841, 21], ['task988_pib_translation_oriya_english.json', 46.56435643564357, 123], ['task1724_civil_comments_insult_classification.json', 1.0, 1], ['task669_ambigqa_answer_generation.json', 5.584158415841584, 28], ['task1257_ted_translation_pl_ja.json', 48.12871287128713, 201], ['task1065_pib_translation_punjabi_telugu.json', 274.8712871287129, 1044], ['task1255_ted_translation_it_pt.json', 29.742574257425744, 158], ['task310_race_classification.json', 1.0, 1], ['task069_abductivenli_classification.json', 2.0, 2], ['task771_pawsx_korean_text_modification.json', 76.25742574257426, 142], ['task371_synthetic_product_of_list.json', 43.445544554455445, 73], ['task1005_pib_translation_malayalam_punjabi.json', 244.75247524752476, 819], ['task1712_poki_classification.json', 1.0, 1], ['task281_points_of_correspondence.json', 23.99009900990099, 68], ['task1612_sick_label_classification.json', 2.0, 2], ['task1009_pib_translation_bengali_hindi.json', 120.67326732673267, 361], ['task914_bianet_translation.json', 54.68316831683168, 244], ['task1323_open_subtitles_hi_en_translation.json', 7.0495049504950495, 15], ['task787_pawsx_korean_chinese_translation.json', 47.75247524752475, 99], ['task422_persent_sentence_sentiment_verification.json', 1.0, 1], ['task1085_pib_translation_english_marathi.json', 109.88118811881188, 422], ['task1187_politifact_classification.json', 1.0, 1], ['task1044_pib_translation_punjabi_gujarati.json', 292.0, 1174], ['task575_air_dialogue_classification.json', 1.0, 1], ['task985_pib_translation_hindi_oriya.json', 451.0792079207921, 1530], ['task1130_xcsr_vi_commonsense_mc_classification.json', 1.0, 1], ['task173_spl_translation_en_it.json', 18.297029702970296, 33], ['task502_scruples_anecdotes_whoiswrong_verification.json', 1.0, 1], ['task1145_xcsr_jap_commonsense_mc_classification.json', 1.0, 1], ['task926_coached_conv_pref_word_generation.json', 4.0, 13], ['task1373_newscomm_translation.json', 42.40594059405941, 104], ['task1495_adverse_drug_event_classification.json', 4.0, 4], ['task805_pawsx_german_chinese_translation.json', 47.75247524752475, 99], ['task1614_sick_text_modify.json', 10.544554455445544, 32], ['task659_tep_fa_en_translation.json', 8.94059405940594, 23], ['task057_multirc_classify_incorrect_answer.json', 2.0, 2], ['task1503_hatexplain_classification.json', 1.3762376237623761, 4], ['task1421_mathqa_other.json', 1.0, 1], ['task633_dbpedia_14_answer_generation.json', 2.0, 2], ['task106_scruples_ethical_judgment.json', 1.0, 1], ['task1201_atomic_classification_xintent.json', 1.0, 1], ['task767_craigslist_bargains_classification.json', 1.5742574257425743, 2], ['task619_ohsumed_abstract_title_generation.json', 23.297029702970296, 51], ['task1203_atomic_classification_xreact.json', 1.0, 1], ['task1418_bless_semantic_relation_classification.json', 1.2574257425742574, 2], ['task1559_blimp_binary_classification.json', 1.0, 1], ['task1058_pib_translation_urdu_english.json', 42.89108910891089, 120], ['task689_mmmlu_answer_generation_college_mathematics.json', 1.0, 1], ['task1113_ted_translation_he_fa.json', 113.95049504950495, 645], ['task092_check_prime_classification.json', 1.0, 1], ['task1597_nyc_slot_filling.json', 17.495049504950494, 25], ['task1344_glue_entailment_classification.json', 2.0, 2], ['task1137_xcsr_pt_commonsense_mc_classification.json', 1.0, 1], ['task1032_pib_translation_telugu_bengali.json', 148.3960396039604, 456], ['task1677_xquad-ca_translation.json', 22.346534653465348, 60], ['task1482_gene_extraction_chemprot_dataset.json', 6.762376237623762, 20], ['task1261_ted_translation_pl_gl.json', 29.77227722772277, 79], ['task467_parsinlu_rc_answer_generation.json', 37.26732673267327, 147], ['task241_tweetqa_classification.json', 1.0, 1], ['task797_pawsx_spanish_french_translation.json', 37.00990099009901, 64], ['task313_europarl_en_sv_translation.json', 46.07920792079208, 203], ['task448_opus_paracrawl_en_tl_translation.json', 70.88118811881188, 291], ['task1378_quarel_correct_answer_generation.json', 3.0693069306930694, 10], ['task943_copa_mr_commonsense_cause_effect.json', 1.0, 1], ['task1124_alt_ja_lo_translation.json', 370.4059405940594, 805], ['task782_pawsx_english_japanese_translation.json', 55.68316831683168, 99], ['task1615_sick_tclassify_b_relation_a.json', 6.653465346534653, 8], ['task421_persent_sentence_sentiment_classification.json', 2.4356435643564356, 3], ['task695_mmmlu_answer_generation_electrical_engineering.json', 1.0, 1], ['task524_parsinlu_food_aspect_classification.json', 1.3762376237623761, 3], ['task1330_open_subtitles_en_te_translation.json', 85.8019801980198, 316], ['task046_miscellaneous_question_typing.json', 2.366336633663366, 4], ['task1286_openbookqa_question_answering.json', 1.0, 1], ['task1574_amazon_reviews_multi_language_identification.json', 1.1584158415841583, 2], ['task819_pec_sentiment_classification.json', 1.0, 1], ['task1542_every_ith_element_from_starting.json', 27.831683168316832, 181], ['task1108_ted_translation_ar_fa.json', 103.66336633663366, 1223], ['task483_cls_french_dvd_classification.json', 2.0, 2], ['task510_reddit_tifu_title_summarization.json', 13.851485148514852, 32], ['task459_matres_static_classification.json', 1.0, 1], ['task1188_count_max_freq_char.json', 1.0, 1], ['task1393_superglue_copa_text_completion.json', 1.0, 1], ['task648_answer_generation.json', 2.613861386138614, 6], ['task496_semeval_answer_generation.json', 1.0, 1], ['task680_hope_edi_tamil_text_classification.json', 3.910891089108911, 5], ['task1581_eqasc-perturbed_answer_generation.json', 2.881188118811881, 11], ['task1423_mathqa_geometry.json', 1.0, 1], ['task1128_alt_th_ja_translation.json', 75.82178217821782, 303], ['task1377_newscomm_translation.json', 49.73267326732673, 131], ['task122_conala_list_index_addition.json', 33.198019801980195, 43], ['task377_remove_words_of_given_length.json', 9.891089108910892, 15], ['task325_jigsaw_classification_identity_attack.json', 5.089108910891089, 6], ['task1250_ted_translation_it_ar.json', 64.87128712871286, 260], ['task1386_anli_r2_entailment.json', 3.0, 3], ['task1504_hatexplain_answer_generation.json', 8.108910891089108, 41], ['task1112_ted_translation_he_pl.json', 35.0990099009901, 185], ['task1327_qa_zre_answer_generation_from_question.json', 3.871287128712871, 9], ['task1185_xcopa_commonsense_cause_effect_zh.json', 1.0, 1], ['task1224_ted_translation_ja_ar.json', 73.10891089108911, 251], ['task1346_glue_cola_grammatical_correctness_classification.json', 2.0, 2], ['task1271_ted_translation_fa_it.json', 30.88118811881188, 157], ['task960_ancora-ca-ner_named_entity_recognition.json', 175.16831683168317, 396], ['task784_pawsx_korean_french_translation.json', 37.00990099009901, 64], ['task1092_ted_translation_en_pl.json', 33.13861386138614, 121], ['task777_pawsx_english_korean_translation.json', 76.25742574257426, 142], ['task198_mnli_domain_classification.json', 2.0, 2], ['task786_pawsx_korean_german_translation.json', 33.78217821782178, 53], ['task1213_atomic_classification_desires.json', 1.0, 1], ['task1538_malayalam_offenseval_dravidian_classification.json', 2.613861386138614, 3], ['task769_qed_summarization.json', 4.336633663366337, 12], ['task904_hate_speech_offensive_classification.json', 2.0, 2], ['task834_mathdataset_classification.json', 1.0, 1], ['task1075_pib_translation_tamil_telugu.json', 281.94059405940595, 823], ['task434_alt_en_hi_answer_generation.json', 1.0, 1], ['task363_sst2_polarity_classification.json', 2.0, 2], ['task1141_xcsr_zh_commonsense_mc_classification.json', 1.0, 1], ['task373_synthetic_round_tens_place.json', 44.148514851485146, 76], ['task1290_xsum_summarization.json', 31.683168316831683, 80], ['task579_socialiqa_classification.json', 1.0, 1], ['task1239_ted_translation_gl_ja.json', 38.59405940594059, 143], ['task828_copa_commonsense_cause_effect.json', 1.0, 1], ['task1585_root09_hypernym_generation.json', 1.386138613861386, 3], ['task696_mmmlu_answer_generation_elementary_mathematics.json', 1.0, 1], ['task588_amazonfood_rating_classification.json', 2.0, 2], ['task991_pib_translation_english_tamil.json', 161.30693069306932, 567], ['task1184_xcopa_commonsense_reasoning_zh.json', 2.0, 2], ['task451_opus_paracrawl_tl_en_translation.json', 41.59405940594059, 187], ['task314_europarl_sv-en_classification.json', 1.0, 1], ['task1007_pib_translation_english_punjabi.json', 433.54455445544556, 1657], ['task1576_amazon_reviews_multi_english_language_classification.json', 2.99009900990099, 4], ['task419_persent_answer_generation.json', 3.9405940594059405, 8], ['task095_conala_max_absolute_value.json', 6.891089108910891, 7], ['task508_scruples_dilemmas_more_ethical_isidentifiable.json', 1.0, 1], ['task1268_ted_translation_fa_ar.json', 68.32673267326733, 337], ['task1584_evalution_meronym_classification.json', 2.0, 2], ['task061_ropes_answer_generation.json', 2.871287128712871, 8], ['task1046_pib_translation_telugu_hindi.json', 128.11881188118812, 407], ['task574_air_dialogue_sentence_generation.json', 15.801980198019802, 44], ['task282_scruples_event_time.json', 5.237623762376238, 8], ['task503_scruples_anecdotes_isanswerable.json', 2.207920792079208, 3], ['task1493_bengali_geopolitical_hate_speech_binary_classification.json', 5.405940594059406, 6], ['task1082_pib_translation_marathi_hindi.json', 108.57425742574257, 427], ['task618_amazonreview_summary_text_generation.json', 15.950495049504951, 44], ['task1589_scifact_classification.json', 1.0, 1], ['task1073_pib_translation_oriya_tamil.json', 171.5742574257426, 486], ['task1244_ted_translation_gl_pl.json', 34.603960396039604, 83], ['task682_online_privacy_policy_text_classification.json', 5.287128712871287, 8], ['task1123_alt_ja_khm_answer_generation.json', 1.0, 1], ['task398_semeval_2018_task1_tweet_joy_detection.json', 1.1683168316831682, 2], ['task1502_hatexplain_classification.json', 2.396039603960396, 4], ['task1531_daily_dialog_type_classification.json', 1.495049504950495, 3], ['task1438_doqa_cooking_answer_generation.json', 24.722772277227723, 52], ['task481_cls_german_music_classification.json', 2.0, 2], ['task521_trivia_question_classification.json', 1.6336633663366336, 2], ['task1492_bengali_religious_hate_speech_binary_classification.json', 4.00990099009901, 5], ['task132_dais_text_modification.json', 9.138613861386139, 16], ['task117_spl_translation_en_de.json', 17.77227722772277, 30], ['task070_abductivenli_incorrect_classification.json', 2.0, 2], ['task1560_blimp_binary_classification.json', 1.0, 1], ['task896_miam_language_classification.json', 1.0, 1], ['task404_grailqa_paraphrase_validation.json', 1.0, 1], ['task226_english_language_answer_relevance_classification.json', 1.0, 1], ['task729_mmmlu_answer_generation_professional_law.json', 1.0, 1], ['task984_pib_translation_marathi_gujarati.json', 263.38613861386136, 1040], ['task1415_youtube_caption_corrections_grammar_correction.json', 347.48514851485146, 381], ['task1583_bless_meronym_classification.json', 2.0, 2], ['task976_pib_indian_language_identification.json', 2.5643564356435644, 4], ['task1229_ted_translation_es_he.json', 71.99009900990099, 275], ['task1324_open_subtitles_te_en_translation.json', 9.831683168316832, 34], ['task484_cls_french_music_classification.json', 2.0, 2], ['task393_plausible_result_generation.json', 7.35, 17], ['task1096_ted_translation_ja_it.json', 30.277227722772277, 98], ['task1566_propara_structured_text_generation.json', 15.069306930693068, 31], ['task369_synthetic_remove_odds.json', 13.316831683168317, 32], ['task841_para_pdt_de_en_translation.json', 29.07920792079208, 46], ['task192_hotpotqa_sentence_generation.json', 37.08910891089109, 83], ['task1127_alt_ja_th_translation.json', 151.97029702970298, 387], ['task640_esnli_classification.json', 1.74, 3], ['task430_senteval_subject_count.json', 2.0, 2], ['task052_multirc_identify_bad_question.json', 2.0, 2], ['task1069_pib_translation_bengali_urdu.json', 136.72277227722773, 359], ['task1364_hans_answer_generation.json', 7.455445544554456, 10], ['task1043_pib_translation_gujarati_punjabi.json', 282.76237623762376, 1263], ['task907_dialogre_identify_relationships.json', 4.0, 4], ['task1018_pib_translation_malayalam_hindi.json', 128.1881188118812, 298], ['task1238_ted_translation_gl_en.json', 20.554455445544555, 121], ['task779_pawsx_english_spanish_translation.json', 34.75247524752475, 57], ['task224_scruples_anecdotes_ethical_judgment.json', 2.1881188118811883, 3], ['task1646_dataset_card_for_catalonia_independence_corpus_text_classification.json', 2.1584158415841586, 3], ['task798_pawsx_spanish_german_translation.json', 33.78217821782178, 53], ['task852_synthetic_multiply_odds.json', 44.960396039603964, 83], ['task803_pawsx_german_french_translation.json', 37.00990099009901, 64], ['task171_spl_translation_en_es.json', 18.693069306930692, 34], ['task1351_opus100_translation_gu_en.json', 22.85148514851485, 88], ['task119_semeval_2019_task10_geometric_mathematical_answer_generation.json', 1.0, 1], ['task1235_ted_translation_he_ja.json', 47.43564356435643, 502], ['task242_tweetqa_classification.json', 1.0, 1], ['task690_mmmlu_answer_generation_college_medicine.json', 1.0, 1], ['task761_app_review_classification.json', 2.0, 2], ['task1126_alt_ja_lo_answer_generation.json', 1.0, 1], ['task712_mmmlu_answer_generation_high_school_world_history.json', 1.0, 1], ['task1551_every_ith_element_from_kth_element.json', 22.198019801980198, 112], ['task336_hateeval_classification_aggresive_es.json', 3.9504950495049505, 5], ['task785_pawsx_korean_spanish_translation.json', 34.75247524752475, 57], ['task534_farstail_entailment.json', 1.0, 1], ['task1628_copa_hr_question_answering.json', 11.811881188118813, 27], ['task1603_smcalflow_sentence_generation.json', 13.03960396039604, 45], ['task869_cfq_mcd1_sql_to_explanation.json', 2.0, 2], ['task621_ohsumed_yes_no_numerical_answer_generation.json', 1.0, 1], ['task1387_anli_r3_entailment.json', 3.0, 3], ['task1371_newscomm_translation.json', 42.693069306930695, 100], ['task1014_pib_translation_telugu_gujarati.json', 321.66336633663366, 1134], ['task1104_ted_translation_es_pt.json', 26.663366336633665, 116], ['task1686_menyo20k_translation.json', 26.643564356435643, 149], ['task881_schema_guided_dstc8_classification.json', 2.633663366336634, 4], ['task124_conala_pair_averages.json', 40.801980198019805, 83], ['task1050_pib_translation_telugu_malayalam.json', 136.4257425742574, 565], ['task1546_conll2002_location_name_extraction_answer_generation.json', 1.8415841584158417, 15], ['task724_mmmlu_answer_generation_moral_scenarios.json', 1.0, 1], ['task676_ollie_relationship_answer_generation.json', 2.4752475247524752, 5], ['task401_numeric_fused_head_reference.json', 1.5445544554455446, 4], ['task290_tellmewhy_question_answerability.json', 2.495049504950495, 3], ['task1254_ted_translation_it_fa.json', 102.79207920792079, 445], ['task309_race_answer_generation.json', 1.0, 1], ['task746_yelp_restaurant_review_classification.json', 1.0, 1], ['task1140_xcsr_pl_commonsense_mc_classification.json', 1.0, 1], ['task1189_check_char_in_string.json', 2.0, 2], ['task694_mmmlu_answer_generation_econometrics.json', 1.0, 1], ['task1391_winogrande_easy_answer_generation.json', 1.0, 1], ['task569_recipe_nlg_text_generation.json', 7.930693069306931, 24], ['task656_quran_en_fa_translation.json', 140.74257425742573, 553], ['task1313_amazonreview_polarity_classification.json', 1.0, 1], ['task504_count_all_alphabetical_elements_in_list.json', 2.633663366336634, 3], ['task1659_title_generation.json', 26.91089108910891, 102], ['task758_msr_sqa_question_answer_generation.json', 80.00990099009901, 619], ['task1729_personachat_generate_next.json', 13.198019801980198, 22], ['task799_pawsx_spanish_chinese_translation.json', 47.75247524752475, 99], ['task038_qasc_combined_fact.json', 12.871287128712872, 29], ['task1237_ted_translation_he_ar.json', 85.97029702970298, 301], ['task054_multirc_write_correct_answer.json', 9.811881188118813, 48], ['task1481_gene_extraction_bc2gm_dataset.json', 5.267326732673268, 13], ['task741_lhoestq_answer_generation_place.json', 4.782178217821782, 15], ['task856_conv_ai_2_classification.json', 1.0, 1], ['task172_spl_translation_en_fa.json', 44.386138613861384, 81], ['task374_synthetic_pos_or_neg_calculation.json', 29.15841584158416, 53], ['task614_glucose_cause_event_detection.json', 21.821782178217823, 37], ['task795_pawsx_spanish_english_translation.json', 29.287128712871286, 46], ['task755_find_longest_substring_and_replace_its_sorted_lowercase_version_in_both_lists.json', 33.94059405940594, 70], ['task163_count_words_ending_with_letter.json', 2.0, 2], ['task1557_jfleg_answer_generation.json', 22.03960396039604, 52], ['task1275_ted_translation_pt_ja.json', 37.89108910891089, 157], ['task1590_diplomacy_text_generation.json', 30.059405940594058, 236], ['task490_mwsc_options_generation.json', 8.96, 13], ['task340_winomt_classification_gender_pro.json', 1.4752475247524752, 2], ['task512_twitter_emotion_classification.json', 1.0, 1], ['task801_pawsx_german_english_translation.json', 29.287128712871286, 46], ['task392_inverse_causal_relationship.json', 3.495049504950495, 4], ['task227_clariq_classification.json', 1.0, 1], ['task1012_pib_translation_punjabi_hindi.json', 132.7029702970297, 306], ['task1570_cmrc2018_answer_generation.json', 22.336633663366335, 116], ['task094_conala_calculate_mean.json', 7.079207920792079, 8], ['task391_causal_relationship.json', 3.495049504950495, 4], ['task473_parsinlu_mc_classification.json', 1.0, 1], ['task628_xlwic_word_with_different_meaning_sentence_generation.json', 10.538461538461538, 24], ['task870_msmarco_answer_generation.json', 23.346534653465348, 76], ['task474_parsinlu_mc_classification.json', 3.5544554455445545, 5], ['task084_babi_t1_single_supporting_fact_identify_relevant_fact.json', 3.0594059405940595, 4], ['task1446_farthest_integers.json', 3.8217821782178216, 4], ['task1662_cedr_ru_classification.json', 1.3564356435643565, 2], ['task1016_pib_translation_tamil_punjabi.json', 249.5049504950495, 904], ['task249_enhanced_wsc_pronoun_disambiguation.json', 3.217821782178218, 10], ['task1627_copa_hr_classification.json', 1.0, 1], ['task1347_glue_sts-b_similarity_classification.json', 2.0, 2], ['task1592_yahoo_answers_topics_classfication.json', 2.0, 2], ['task384_socialiqa_question_classification.json', 1.0, 1], ['task1266_ted_translation_fa_ja.json', 48.89108910891089, 198], ['task185_snli_contradiction_to_neutral_text_modification.json', 9.930693069306932, 24], ['task1025_pib_translation_bengali_punjabi.json', 256.36633663366337, 1018], ['task752_svamp_multiplication_question_answering.json', 4.366336633663367, 9], ['task940_copa_gu_commonsense_reasoning.json', 20.0, 20], ['task902_deceptive_opinion_spam_classification.json', 1.0, 1], ['task253_spl_translation_en_zh.json', 23.485148514851485, 38], ['task542_alt_translation_ja_en.json', 31.178217821782177, 71], ['task977_pib_translation_oriya_urdu.json', 223.78217821782178, 626], ['task714_mmmlu_answer_generation_human_sexuality.json', 1.0, 1], ['task1273_ted_translation_fa_pt.json', 28.742574257425744, 104], ['task543_alt_translation_bh_en.json', 34.495049504950494, 85], ['task1168_xcopa_commonsense_reasoning_ht.json', 2.0, 2], ['task261_spl_translation_es_en.json', 14.099009900990099, 28], ['task1094_ted_translation_en_pt.json', 24.514851485148515, 78], ['task1723_civil_comments_sexuallyexplicit_classification.json', 1.0, 1], ['task262_spl_translation_ja_en.json', 14.089108910891088, 28], ['task792_pawsx_french_german_translation.json', 33.78217821782178, 53], ['task256_spl_translation_de_en.json', 14.049504950495049, 28], ['task879_schema_guided_dstc8_classification.json', 1.0, 1], ['task1399_obqa_answer_generation.json', 5.465346534653466, 22], ['task626_xlwic_sentence_based_on_given_word_sentence_generation.json', 10.306930693069306, 30], ['task701_mmmlu_answer_generation_high_school_computer_science.json', 1.0, 1], ['task1706_ljspeech_classification.json', 1.0, 1], ['task115_help_advice_classification.json', 1.0, 1], ['task1285_kpa_keypoint_matching.json', 1.0, 1], ['task273_europarl_classification.json', 1.0, 1], ['task292_storycommonsense_character_text_generation.json', 4.594059405940594, 14], ['task660_mizan_fa_en_translation.json', 22.22772277227723, 81], ['task748_glucose_reverse_cause_event_detection.json', 22.059405940594058, 35], ['task974_prachathai67k_sentiment_classification.json', 1.0, 1], ['task889_goemotions_classification.json', 1.188118811881188, 2], ['task516_senteval_conjoints_inversion.json', 1.5445544554455446, 2], ['task387_semeval_2018_task3_irony_classification.json', 1.8514851485148516, 2], ['task298_storycloze_correct_end_classification.json', 1.0, 1], ['task605_find_the_longest_common_subsequence_in_two_lists.json', 59.21782178217822, 134], ['task284_imdb_classification.json', 1.0, 1], ['task923_event2mind_classifier.json', 2.0, 2], ['task997_pib_translation_bengali_oriya.json', 371.6732673267327, 1052], ['task1623_disfl_qa_disfluent_question_classification.json', 1.9702970297029703, 3]]

def get_max_new_tokens(dataset_path, task=''):
    if not task:
        task = dataset_path.split('/')[-2]
    mean, max = 0, 0
    for name, m, mm in LENGTH:
        if task in name:
            mean, max = int(m), int(mm)
            break
    if mean and max:
        mean += 3
        max += 3

        for top in range(50, 550, 50):
            if max < top:
                return top
        return 500
    else:
        print("cannot find file!!!")
            
        
if __name__ == "__main__":
    tokenizer = get_llama_tokenizer()
    files = list(os.listdir("/share/jiziwei/natural-instructions-2.8/tasks"))
    print(len(files))
    all_num = 0

    tasks = []
    with open('/share/jiziwei/natural-instructions-2.8/selected_tasks.txt') as f:
        for l in f.readlines():
            if "#" not in l:
                tasks.append(l.strip())
    print(tasks)           
    # no_tasks = set()
    results = []
    for i, file in tqdm(enumerate(files)):
        with open(f"/share/jiziwei/natural-instructions-2.8/tasks/{file}") as f:
            if not file.endswith("json"):
                continue
            # try:
            nums = []
            data = json.load(f)
            if any([c not in tasks for c in data['Categories']]):
                continue
            assert len(data['Categories']) == 1
            category = "_".join(data['Categories'][0].strip().split())
            if file in ["task288_gigaword_summarization.json"]:
                data['Definition'] = [data['Definition'][1]]
            if len(data['Definition']) > 1:
                print(file, data['Definition'])
            assert len(data['Definition']) == 1
            instruction = data['Definition'][0]
            instances = data['Instances']
            for i, instance in enumerate(instances):
                if i > 100:
                    break
                nums.append(len(tokenizer.tokenize(instance['output'][0])))
            results.append([file, np.mean(nums), np.max(nums)])
    print(results)