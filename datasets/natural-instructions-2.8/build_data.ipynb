{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1614\n",
      "['Question Answering', 'Overlap Extraction', 'Program Execution', 'Text to Code', 'Data to Text', 'Code to Text', 'Translation', 'Paraphrasing', 'Explanation', 'Title Generation', 'Dialogue Generation', 'Grammar Error Correction', 'Number Conversion', 'Summarization', 'Sentence Compression', 'Preposition Prediction', 'Question Understanding', 'Answerability Classification', 'Text Quality Evaluation', 'Toxic Language Detection', 'Coreference Resolution', 'Answer Verification', 'Coherence Classification', 'Mathematics', 'Spelling Error Detection', 'Grammar Error Detection', 'Ethics Classification', 'Spam Classification', 'Linguistic Probing', 'Text Categorization', 'Commonsense Classification', 'Word Semantics', 'Text Matching', 'Information Extraction', 'Textual Entailment', 'Sentiment Analysis', 'Sentence Composition', 'Sentence Ordering', 'Paper Review', 'Language Identification', 'Stereotype Detection', 'Gender Classification', 'Section Classification', 'Dialogue Act Recognition', 'Irony Detection', 'Cause Effect Classification', 'Named Entity Recognition', 'Speaker Identification', 'Speaker Relation Classification', 'Dialogue State Tracking', 'Punctuation Error Detection', 'Word Relation Classification', 'Fact Verification', 'Discourse Relation Classification', 'Entity Relation Classification', 'Discourse Connective Identification', 'Stance Detection', '']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e75fa82953046a4bdca6e74c5d8292f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = list(os.listdir(\"/share/jiziwei/natural-instructions-2.8/tasks\"))\n",
    "print(len(files))\n",
    "all_num = 0\n",
    "\n",
    "tasks = []\n",
    "with open('/share/jiziwei/natural-instructions-2.8/selected_tasks.txt') as f:\n",
    "    for l in f.readlines():\n",
    "        if \"#\" not in l:\n",
    "            tasks.append(l.strip())\n",
    "print(tasks)           \n",
    "# no_tasks = set()\n",
    "for i, file in tqdm(enumerate(files)):\n",
    "    with open(f\"/share/jiziwei/natural-instructions-2.8/tasks/{file}\") as f:\n",
    "        if not file.endswith(\"json\"):\n",
    "            continue\n",
    "        # try:\n",
    "        data = json.load(f)\n",
    "        if any([c not in tasks for c in data['Categories']]):\n",
    "            continue\n",
    "        assert len(data['Categories']) == 1\n",
    "        category = \"_\".join(data['Categories'][0].strip().split())\n",
    "        if file in [\"task288_gigaword_summarization.json\"]:\n",
    "            data['Definition'] = [data['Definition'][1]]\n",
    "        if len(data['Definition']) > 1:\n",
    "            print(file, data['Definition'])\n",
    "        assert len(data['Definition']) == 1\n",
    "        instruction = data['Definition'][0]\n",
    "        instances = data['Instances']\n",
    "        X_train, X_test_val, y_train, y_test_val = train_test_split(instances, list(range(len(instances))), test_size=0.2, random_state=42)\n",
    "        X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5, random_state=42)\n",
    "        # except:\n",
    "        #     print(\"wrong\", file)\n",
    "        file = file[:-5]\n",
    "        os.makedirs(f\"/share/jiziwei/natural-instructions-2.8/processed/{category}/{file}\", exist_ok=True)\n",
    "        with jsonlines.open(f\"/share/jiziwei/natural-instructions-2.8/processed/{category}/{file}/train.jsonl\", 'w') as writer:\n",
    "            for line in X_train:\n",
    "                line2 = {\"id\": line[\"id\"], \n",
    "                         \"question\": f\"{instruction}\\n{line['input']}\", \n",
    "                         \"answer\": line[\"output\"], }\n",
    "                writer.write(line2)\n",
    "                \n",
    "        with jsonlines.open(f\"/share/jiziwei/natural-instructions-2.8/processed/{category}/{file}/test.jsonl\", 'w') as writer:\n",
    "            for line in X_test:\n",
    "                line2 = {\"id\": line[\"id\"], \n",
    "                         \"question\": f\"{instruction}\\n{line['input']}\", \n",
    "                         \"answer\": line[\"output\"], }\n",
    "                writer.write(line2)\n",
    "\n",
    "        with jsonlines.open(f\"/share/jiziwei/natural-instructions-2.8/processed/{category}/{file}/val.jsonl\", 'w') as writer:\n",
    "            for line in X_val:\n",
    "                line2 = {\"id\": line[\"id\"], \n",
    "                         \"question\": f\"{instruction}\\n{line['input']}\", \n",
    "                         \"answer\": line[\"output\"], }\n",
    "                writer.write(line2)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
